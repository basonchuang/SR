{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27204d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T06:57:00.221101Z",
     "start_time": "2022-07-01T06:56:59.062296Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.python.ops import ctc_ops\n",
    "from collections import Counter\n",
    "import os, time, glob, json, torch\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f4d23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T06:57:00.558982Z",
     "start_time": "2022-07-01T06:57:00.227403Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 14:57:00.228866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-01 14:57:00.288189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.288310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-07-01 14:57:00.288495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 14:57:00.289448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 14:57:00.290372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-01 14:57:00.290516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-01 14:57:00.291489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-01 14:57:00.292014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-01 14:57:00.294063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 14:57:00.294145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.294258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.294311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-07-01 14:57:00.295062: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-07-01 14:57:00.316237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2799925000 Hz\n",
      "2022-07-01 14:57:00.316815: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631524b1b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-01 14:57:00.316829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-01 14:57:00.316983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.317071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-07-01 14:57:00.317105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 14:57:00.317115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 14:57:00.317124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-01 14:57:00.317133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-01 14:57:00.317142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-01 14:57:00.317151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-01 14:57:00.317161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 14:57:00.317205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.317285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.317335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-07-01 14:57:00.317358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 14:57:00.554378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-01 14:57:00.554394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-07-01 14:57:00.554398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-07-01 14:57:00.554511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.554635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.554717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:00.554789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2022-07-01 14:57:00.555952: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631534972e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-01 14:57:00.555962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n"
     ]
    }
   ],
   "source": [
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    physical_gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)] \n",
    ")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abe8819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T07:02:31.572054Z",
     "start_time": "2022-07-01T06:57:00.565844Z"
    },
    "code_folding": [
     1,
     14,
     46,
     64,
     80,
     88,
     105,
     142,
     156,
     170,
     250,
     316,
     359,
     469,
     473
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/data_sr/data/1618243237.json\n",
      "dataset/data_sr/data/1618243179.json\n",
      "dataset/data_sr/data/1618243233.json\n",
      "字表大小: 2\n",
      "WARNING:tensorflow:From /tmp/ipykernel_890346/661619559.py:460: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_890346/661619559.py:404: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_890346/661619559.py:415: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/rnn.py:455: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/rnn_cell_impl.py:744: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "n_character:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 14:57:01.953667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:01.953768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-07-01 14:57:01.953808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-01 14:57:01.953819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-01 14:57:01.953829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-01 14:57:01.953838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-01 14:57:01.953847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-01 14:57:01.953857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-01 14:57:01.953867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-01 14:57:01.953912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:01.953991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:01.954040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-07-01 14:57:01.954058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-01 14:57:01.954062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-07-01 14:57:01.954064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-07-01 14:57:01.954097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:01.954176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-01 14:57:01.954236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpt: model/saver.cpkt-213\n",
      "INFO:tensorflow:Restoring parameters from model/saver.cpkt-213\n",
      "213\n",
      "\n",
      "===========Run training epoch===========\n",
      "\n",
      "epoch start: 213 total epochs=  214\n",
      "total loop  576 in one epoch， 32 items in one loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 15:01:02.577497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/214, batch: 0, train_cost: 2.221, train_ler: 0.000, time: 80.29 sec\n",
      "Epoch 213/214, batch: 1, train_cost: 2.443, train_ler: 0.000, time: 80.79 sec\n",
      "Epoch 213/214, batch: 2, train_cost: 1.780, train_ler: 0.000, time: 81.30 sec\n",
      "Epoch 213/214, batch: 3, train_cost: 2.052, train_ler: 0.000, time: 81.79 sec\n",
      "Epoch 213/214, batch: 4, train_cost: 1.916, train_ler: 0.000, time: 82.29 sec\n",
      "Epoch 213/214, batch: 5, train_cost: 2.169, train_ler: 0.000, time: 82.79 sec\n",
      "Epoch 213/214, batch: 6, train_cost: 2.310, train_ler: 0.000, time: 83.29 sec\n",
      "Epoch 213/214, batch: 7, train_cost: 3.257, train_ler: 0.000, time: 83.79 sec\n",
      "Epoch 213/214, batch: 8, train_cost: 2.528, train_ler: 0.000, time: 84.28 sec\n",
      "Epoch 213/214, batch: 9, train_cost: 1.672, train_ler: 0.000, time: 84.78 sec\n",
      "Epoch 213/214, batch: 10, train_cost: 1.871, train_ler: 0.000, time: 85.29 sec\n",
      "Epoch 213/214, batch: 11, train_cost: 2.877, train_ler: 0.000, time: 85.79 sec\n",
      "Epoch 213/214, batch: 12, train_cost: 2.823, train_ler: 0.000, time: 86.27 sec\n",
      "Epoch 213/214, batch: 13, train_cost: 1.872, train_ler: 0.000, time: 86.75 sec\n",
      "Epoch 213/214, batch: 14, train_cost: 2.932, train_ler: 0.000, time: 87.22 sec\n",
      "Epoch 213/214, batch: 15, train_cost: 2.902, train_ler: 0.000, time: 87.72 sec\n",
      "Epoch 213/214, batch: 16, train_cost: 2.404, train_ler: 0.000, time: 88.20 sec\n",
      "Epoch 213/214, batch: 17, train_cost: 2.209, train_ler: 0.000, time: 88.65 sec\n",
      "Epoch 213/214, batch: 18, train_cost: 1.886, train_ler: 0.000, time: 89.13 sec\n",
      "loop: 19 Train cost:  0.09562400579452515\n",
      "Label err rate:  1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dense_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 490>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    540\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel err rate: \u001b[39m\u001b[38;5;124m'\u001b[39m, train_ler)\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m orig, decoded_arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mdense_labels\u001b[49m, dense_decoded):\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# convert to strings\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     decoded_str \u001b[38;5;241m=\u001b[39m dense_to_text(decoded_arr, words)\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(counter))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dense_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#All\n",
    "def get_wavs(wav_path):\n",
    "    wavs = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(wav_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):\n",
    "                # print(filename)\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                # print(filename_path)\n",
    "                wavs.append(filename_path)\n",
    "    return wavs\n",
    " \n",
    " \n",
    "# 获取wav文件对应的翻译文字\n",
    "def get_tran_texts(wavs, tran_path):\n",
    "    tran_texts = []\n",
    "    for wav_file in wavs:\n",
    "        basename = os.path.basename(wav_file)\n",
    "        wav_filename = os.path.splitext(basename)[0]\n",
    "        for tran_file in glob.glob(os.path.join(tran_path, wav_filename + '.json')):\n",
    "            if os.path.exists(tran_file) is False:\n",
    "                continue\n",
    "            try:\n",
    "                with open(tran_file, encoding='utf-8') as fd:\n",
    "                    data = json.load(fd)\n",
    "                    a = 0\n",
    "                    b = 0\n",
    "                    c = 0\n",
    "                    d = 0\n",
    "                    if data['command'] == 'open':\n",
    "                        a = 1\n",
    "                    elif data['command'] == 'close':\n",
    "                        b = 1\n",
    "                    elif data['command'] == 'hold':\n",
    "                        c = 1\n",
    "                    else:\n",
    "                        d = 1\n",
    "                    data = [a,b,c,d]\n",
    "                    tran_texts.append(data)\n",
    "                    fd.close()\n",
    "            except ValueError:\n",
    "                    print(tran_file)\n",
    "    return tran_texts\n",
    " \n",
    " \n",
    "# 获取wav和对应的翻译文字\n",
    "def get_wavs_and_tran_texts(wav_path, tran_path):\n",
    "    wavs = get_wavs(wav_path)\n",
    "    tran_texts = get_tran_texts(wavs, tran_path)\n",
    " \n",
    "    return wavs, tran_texts \n",
    "\n",
    "wav_path = 'dataset/data_sr/train'\n",
    "label_file = 'dataset/data_sr/data'\n",
    "\n",
    "wavs, labels = get_wavs_and_tran_texts(wav_path,label_file)\n",
    "\n",
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "# 将稀疏矩阵的字向量转成文字\n",
    "# tuple是sparse_tuple函数的返回值\n",
    "def sparse_tuple_to_text(tuple, words):\n",
    "    # 索引\n",
    "    indices = tuple[0]\n",
    "    # 字向量\n",
    "    values = tuple[1]\n",
    "    results = [''] * tuple[2][0]\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i][0]\n",
    "        c = values[i]\n",
    "        c = ' ' if c == SPACE_INDEX else words[c]\n",
    "        results[index] = results[index] + c\n",
    " \n",
    "    return results\n",
    " \n",
    " \n",
    "# 将密集矩阵的字向量转成文字\n",
    "def dense_to_text(value, words):\n",
    "    results = ''\n",
    "    for i in range(len(value)):\n",
    "        results += words[value[i]]  # chr(value[i] + FIRST_INDEX)\n",
    "    return results.replace('`', ' ')\n",
    " \n",
    " \n",
    "# 创建序列的稀疏表示\n",
    "def sparse_tuple(sequences, dtype=np.int32):\n",
    "    indices = []\n",
    "    values = []\n",
    " \n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n] * len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    " \n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), indices.max(0)[1] + 1], dtype=np.int64)\n",
    " \n",
    "    # return tf.SparseTensor(indices=indices, values=values, shape=shape)\n",
    "    return indices, values, shape\n",
    " \n",
    " \n",
    "# 将音频数据转为时间序列（列）和MFCC（行）的矩阵，将对应的译文转成字向量\n",
    "def get_mfccs_and_transcriptch(txt_files, wavs, n_input, contexts, chars_map, txt_labels=None):\n",
    "    audio = []\n",
    "    audio_len = []\n",
    "    transcript = []\n",
    "    transcript_len = []\n",
    "    if txt_files != None:\n",
    "        txt_labels = txt_files\n",
    " \n",
    "    for txt_obj, wav_file in zip(txt_labels, wavs):\n",
    "        # load audio and convert to features\n",
    "        audio_data = audiofile_to_input_vector(wav_file, n_input, contexts)\n",
    "        try:\n",
    "            audio_data = audio_data.astype('float32')\n",
    "            # print(chars_map)\n",
    "            audio.append(audio_data)\n",
    "            audio_len.append(np.int32(len(audio_data)))\n",
    "\n",
    "            # load text transcription and convert to numerical array\n",
    "            target = []\n",
    "            if txt_files != None:  # txt_obj是文件\n",
    "                target = get_labels_vector(txt_obj, chars_map)\n",
    "            else:\n",
    "                target = get_labels_vector(None, chars_map, txt_obj)  # txt_obj是labels\n",
    "            # target = text_to_char_array(target)\n",
    "            transcript.append(target)\n",
    "            transcript_len.append(len(target))\n",
    "        except AttributeError:\n",
    "            print(audio_data)\n",
    " \n",
    "    audio = np.asarray(audio,dtype=object)\n",
    "    audio_len = np.asarray(audio_len)\n",
    "    transcript = np.asarray(transcript)\n",
    "    transcript_len = np.asarray(transcript_len)\n",
    "    return audio, audio_len, transcript, transcript_len\n",
    " \n",
    " \n",
    "# 将字符转成向量，其实就是根据字找到字在chars_map中所应对的下标\n",
    "def get_labels_vector(txt_file, chars_map, txt_label=None):\n",
    "    words_size = len(chars_map)\n",
    " \n",
    "    to_num = lambda word: chars_map.get(word, words_size)\n",
    " \n",
    "    if txt_file != None:\n",
    "        txt_label = get_ch_lable(txt_file)\n",
    " \n",
    "    # print(txt_label)\n",
    "    labels_vector = list(map(to_num, txt_label))\n",
    "    # print(labels_vector)\n",
    "    return labels_vector\n",
    " \n",
    " \n",
    "def get_ch_lable(txt_file):\n",
    "    labels = \"\"\n",
    "    with open(txt_file, 'rb') as f:\n",
    "        for label in f:\n",
    "            # labels =label.decode('utf-8')\n",
    "            labels = labels + label.decode('gb2312')\n",
    "            # labels.append(label.decode('gb2312'))\n",
    " \n",
    "    return labels\n",
    " \n",
    " \n",
    "# 将音频信息转成MFCC特征\n",
    "# 参数说明---audio_filename：音频文件   numcep：梅尔倒谱系数个数\n",
    "#       numcontext：对于每个时间段，要包含的上下文样本个数\n",
    "def audiofile_to_input_vector(audio_filename, numcep, numcontext):\n",
    "    # 加载音频文件\n",
    "    try:\n",
    "        fs, audio = wav.read(audio_filename)\n",
    "        # 获取MFCC系数\n",
    "        orig_inputs = mfcc(audio, samplerate=fs, numcep=numcep)\n",
    "        # 打印MFCC系数的形状，得到比如(955, 26)的形状\n",
    "        # 955表示时间序列，26表示每个序列的MFCC的特征值为26个\n",
    "        # 这个形状因文件而异，不同文件可能有不同长度的时间序列，但是，每个序列的特征值数量都是一样的\n",
    "        #print('orig_inputs shape', np.shape(orig_inputs))\n",
    "\n",
    "        # 因为我们使用双向循环神经网络来训练,它的输出包含正、反向的结\n",
    "        # 果,相当于每一个时间序列都扩大了一倍,所以\n",
    "        # 为了保证总时序不变,使用orig_inputs =\n",
    "        # orig_inputs[::2]对orig_inputs每隔一行进行一次\n",
    "        # 取样。这样被忽略的那个序列可以用后文中反向\n",
    "        # RNN生成的输出来代替,维持了总的序列长度。\n",
    "        orig_inputs = orig_inputs[::2]  # (478, 26)\n",
    "        # print(np.shape(orig_inputs))\n",
    "        # 因为我们讲解和实际使用的numcontext=9，所以下面的备注我都以numcontext=9来讲解\n",
    "        # 这里装的就是我们要返回的数据，因为同时要考虑前9个和后9个时间序列，\n",
    "        # 所以每个时间序列组合了19*26=494个MFCC特征数\n",
    "        train_inputs = np.array([], np.float32)\n",
    "        train_inputs.resize((orig_inputs.shape[0], numcep + 2 * numcep * numcontext))\n",
    "        #print('train_inputs shape', np.shape(train_inputs))#)(478, 494)\n",
    "\n",
    "        # Prepare pre-fix post fix context\n",
    "        empty_mfcc = np.array([])\n",
    "        empty_mfcc.resize((numcep))\n",
    "\n",
    "        # Prepare train_inputs with past and future contexts\n",
    "        # time_slices保存的是时间切片，也就是有多少个时间序列\n",
    "        time_slices = range(train_inputs.shape[0])\n",
    "\n",
    "        # context_past_min和context_future_max用来计算哪些序列需要补零\n",
    "        context_past_min = time_slices[0] + numcontext\n",
    "        context_future_max = time_slices[-1] - numcontext\n",
    "\n",
    "        # 开始遍历所有序列\n",
    "        for time_slice in time_slices:\n",
    "            # 对前9个时间序列的MFCC特征补0，不需要补零的，则直接获取前9个时间序列的特征\n",
    "            need_empty_past = max(0, (context_past_min - time_slice))\n",
    "            empty_source_past = list(empty_mfcc for empty_slots in range(need_empty_past))\n",
    "            data_source_past = orig_inputs[max(0, time_slice - numcontext):time_slice]\n",
    "            assert (len(empty_source_past) + len(data_source_past) == numcontext)\n",
    "\n",
    "            # 对后9个时间序列的MFCC特征补0，不需要补零的，则直接获取后9个时间序列的特征\n",
    "            need_empty_future = max(0, (time_slice - context_future_max))\n",
    "            empty_source_future = list(empty_mfcc for empty_slots in range(need_empty_future))\n",
    "            data_source_future = orig_inputs[time_slice + 1:time_slice + numcontext + 1]\n",
    "            assert (len(empty_source_future) + len(data_source_future) == numcontext)\n",
    "\n",
    "            # 前9个时间序列的特征\n",
    "            if need_empty_past:\n",
    "                past = np.concatenate((empty_source_past, data_source_past))\n",
    "            else:\n",
    "                past = data_source_past\n",
    "            # 后9个时间序列的特征\n",
    "            if need_empty_future:\n",
    "                future = np.concatenate((data_source_future, empty_source_future))\n",
    "            else:\n",
    "                future = data_source_future\n",
    "\n",
    "            # 将前9个时间序列和当前时间序列以及后9个时间序列组合\n",
    "            past = np.reshape(past, numcontext * numcep)\n",
    "            now = orig_inputs[time_slice]\n",
    "            future = np.reshape(future, numcontext * numcep)\n",
    "\n",
    "            train_inputs[time_slice] = np.concatenate((past, now, future))\n",
    "            assert (len(train_inputs[time_slice]) == numcep + 2 * numcep * numcontext)\n",
    "\n",
    "        # 将数据使用正太分布标准化，减去均值然后再除以方差\n",
    "        train_inputs = (train_inputs - np.mean(train_inputs)) / np.std(train_inputs)\n",
    "\n",
    "        return train_inputs\n",
    "    except ValueError:\n",
    "        print(audio_filename)\n",
    "    \n",
    " \n",
    "#对齐处理\n",
    "def pad_sequences(sequences, maxlen=None, dtype=np.float32,\n",
    "                  padding='post', truncating='post', value=0.):\n",
    "    #[478 512 503 406 481 509 422 465]\n",
    "    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)\n",
    " \n",
    "    nb_samples = len(sequences)\n",
    " \n",
    "    #maxlen，该批次中，最长的序列长度\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    " \n",
    "    # 在下面的主循环中，从第一个非空序列中获取样本形状以检查一致性\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    " \n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # 序列为空，跳过\n",
    " \n",
    "        #post表示后补零，pre表示前补零\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    " \n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    " \n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    " \n",
    "    return x, lengths\n",
    "\n",
    "# 字表\n",
    "all_words = []\n",
    "for label in labels:\n",
    "    #print(label)\n",
    "    all_words += [word for word in label]\n",
    "counter = Counter(all_words)\n",
    "words = sorted(counter)\n",
    "words_size= len(words)\n",
    "chars_map = dict(zip(words, range(words_size)))\n",
    " \n",
    "print('字表大小:', words_size)\n",
    "\n",
    "# 梅尔倒谱系数的个数\n",
    "n_input = 26\n",
    "# 对于每个时间序列，要包含上下文样本的个数\n",
    "contexts = 9\n",
    "# batch大小\n",
    "batch_size = 32\n",
    " \n",
    "\n",
    "def next_batch(wavs, labels, start_idx=0, batch_size=1):\n",
    "    filesize = len(labels)\n",
    "    # 计算要获取的序列的开始和结束下标\n",
    "    end_idx = min(filesize, start_idx + batch_size)\n",
    "    idx_list = range(start_idx, end_idx)\n",
    "    # 获取要训练的音频文件路径和对于的译文\n",
    "    txt_labels = [labels[i] for i in idx_list]\n",
    "    wavs = [wavs[i] for i in idx_list]\n",
    "    # 将音频文件转成要训练的数据\n",
    "    (source, audio_len, target, transcript_len) = get_mfccs_and_transcriptch(None,\n",
    "                                                                             wavs,\n",
    "                                                                             n_input,\n",
    "                                                                             contexts, chars_map, txt_labels)\n",
    " \n",
    "    start_idx += batch_size\n",
    "    # Verify that the start_idx is not largVerify that the start_idx is not ler than total available sample size\n",
    "    if start_idx >= filesize:\n",
    "        start_idx = -1\n",
    " \n",
    "    # Pad input to max_time_step of this batch\n",
    "    # 如果多个文件将长度统一，支持按最大截断或补0\n",
    "    source, source_lengths = pad_sequences(source)\n",
    "    # 返回序列的稀疏表示\n",
    "    sparse_labels = sparse_tuple(target)\n",
    " \n",
    "    return start_idx, source, source_lengths, sparse_labels\n",
    "\n",
    "b_stddev = 0.046875\n",
    "h_stddev = 0.046875\n",
    " \n",
    "n_hidden = 1024\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_5 = 1024\n",
    "n_cell_dim = 1024\n",
    "n_hidden_3 = 2 * 1024\n",
    " \n",
    "keep_dropout_rate = 0.95\n",
    "relu_clip = 20\n",
    " \n",
    "\"\"\"\n",
    "used to create a variable in CPU memory.\n",
    "\"\"\"\n",
    "def variable_on_cpu(name, shape, initializer):\n",
    "    # Use the /cpu:0 device for scoped operations\n",
    "    with tf.device('/CPU:0'):\n",
    "        # Create or get apropos variable\n",
    "        var = tf.compat.v1.get_variable(name=name, shape=shape, initializer=initializer)\n",
    "    return var\n",
    " \n",
    " \n",
    "def BiRNN_model(batch_x, seq_length, n_input, contexts, n_character, keep_dropout):\n",
    "    # batch_x_shape: [batch_size, amax_stepsize, n_input + 2 * n_input * contexts]\n",
    "    batch_x_shape = tf.shape(batch_x)\n",
    " \n",
    "    # 将输入转成时间序列优先\n",
    "    batch_x = tf.transpose(batch_x, [1, 0, 2])\n",
    "    # 再转成2维传入第一层\n",
    "    # [amax_stepsize * batch_size, n_input + 2 * n_input * contexts]\n",
    "    batch_x = tf.reshape(batch_x, [-1, n_input + 2 * n_input * contexts])\n",
    " \n",
    "    # 使用clipped RELU activation and dropout.\n",
    "    # 1st layer\n",
    "    with tf.name_scope('fc1'):\n",
    "        b1 = variable_on_cpu('b1', [n_hidden_1], tf.random_normal_initializer(stddev=b_stddev))\n",
    "        h1 = variable_on_cpu('h1', [n_input + 2 * n_input * contexts, n_hidden_1],\n",
    "                             tf.random_normal_initializer(stddev=h_stddev))\n",
    "        layer_1 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(batch_x, h1), b1)), relu_clip)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_dropout)\n",
    " \n",
    "    # 2nd layer\n",
    "    with tf.name_scope('fc2'):\n",
    "        b2 = variable_on_cpu('b2', [n_hidden_2], tf.random_normal_initializer(stddev=b_stddev))\n",
    "        h2 = variable_on_cpu('h2', [n_hidden_1, n_hidden_2], tf.random_normal_initializer(stddev=h_stddev))\n",
    "        layer_2 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_1, h2), b2)), relu_clip)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_dropout)\n",
    " \n",
    "    # 3rd layer\n",
    "    with tf.name_scope('fc3'):\n",
    "        b3 = variable_on_cpu('b3', [n_hidden_3], tf.random_normal_initializer(stddev=b_stddev))\n",
    "        h3 = variable_on_cpu('h3', [n_hidden_2, n_hidden_3], tf.random_normal_initializer(stddev=h_stddev))\n",
    "        layer_3 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(layer_2, h3), b3)), relu_clip)\n",
    "        layer_3 = tf.nn.dropout(layer_3, keep_dropout)\n",
    " \n",
    "    # 双向rnn\n",
    "    with tf.name_scope('lstm'):\n",
    "        # Forward direction cell:\n",
    "        lstm_fw_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_fw_cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm_fw_cell,\n",
    "                                                     input_keep_prob=keep_dropout)\n",
    "        # Backward direction cell:\n",
    "        lstm_bw_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_cell_dim, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_bw_cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm_bw_cell,\n",
    "                                                     input_keep_prob=keep_dropout)\n",
    " \n",
    "        # `layer_3`  `[amax_stepsize, batch_size, 2 * n_cell_dim]`\n",
    "        layer_3 = tf.reshape(layer_3, [-1, batch_x_shape[0], n_hidden_3])\n",
    " \n",
    "        outputs, output_states = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw=lstm_fw_cell,\n",
    "                                                                 cell_bw=lstm_bw_cell,\n",
    "                                                                 inputs=layer_3,\n",
    "                                                                 dtype=tf.float32,\n",
    "                                                                 time_major=True,\n",
    "                                                                 sequence_length=seq_length)\n",
    " \n",
    "        # 连接正反向结果[amax_stepsize, batch_size, 2 * n_cell_dim]\n",
    "        outputs = tf.concat(outputs, 2)\n",
    "        # to a single tensor of shape [amax_stepsize * batch_size, 2 * n_cell_dim]\n",
    "        outputs = tf.reshape(outputs, [-1, 2 * n_cell_dim])\n",
    " \n",
    "    with tf.name_scope('fc5'):\n",
    "        b5 = variable_on_cpu('b5', [n_hidden_5], tf.random_normal_initializer(stddev=b_stddev))\n",
    "        h5 = variable_on_cpu('h5', [(2 * n_cell_dim), n_hidden_5], tf.random_normal_initializer(stddev=h_stddev))\n",
    "        layer_5 = tf.minimum(tf.nn.relu(tf.add(tf.matmul(outputs, h5), b5)), relu_clip)\n",
    "        layer_5 = tf.nn.dropout(layer_5, keep_dropout)\n",
    " \n",
    "    with tf.name_scope('fc6'):\n",
    "        # 全连接层用于softmax分类\n",
    "        b6 = variable_on_cpu('b6', [n_character], tf.random_normal_initializer(stddev=b_stddev))\n",
    "        h6 = variable_on_cpu('h6', [n_hidden_5, n_character], tf.random_normal_initializer(stddev=h_stddev))\n",
    "        layer_6 = tf.add(tf.matmul(layer_5, h6), b6)\n",
    " \n",
    "    # 将2维[amax_stepsize * batch_size, n_character]转成3维 time-major [amax_stepsize, batch_size, n_character].\n",
    "    layer_6 = tf.reshape(layer_6, [-1, batch_x_shape[0], n_character], name=\"pred\")\n",
    "    print('n_character:' + str(n_character))\n",
    "    # Output shape: [amax_stepsize, batch_size, n_character]\n",
    "    return layer_6\n",
    " \n",
    "# input_tensor为输入音频数据，由前面分析可知，它的结构是[batch_size, amax_stepsize, n_input + (2 * n_input * contexts)]\n",
    "#其中，batch_size是batch的长度，amax_stepsize是时序长度，n_input + (2 * n_input * contexts)是MFCC特征数，\n",
    "#batch_size是可变的，所以设为None，由于每一批次的时序长度不固定，所有，amax_stepsize也设为None\n",
    "input_tensor = tf.compat.v1.placeholder(tf.float32, [None, None, n_input + (2 * n_input * contexts)], name='input')\n",
    "# Use sparse_placeholder; will generate a SparseTensor, required by ctc_loss op.\n",
    "#targets保存的是音频数据对应的文本的系数张量，所以用sparse_placeholder创建一个稀疏张量\n",
    "targets = tf.compat.v1.sparse_placeholder(tf.int32, name='label')\n",
    "#seq_length保存的是当前batch数据的时序长度\n",
    "seq_length = tf.compat.v1.placeholder(tf.int32, [None], name='seq_length')\n",
    "#keep_dropout则是dropout的参数\n",
    "keep_dropout= tf.compat.v1.placeholder(tf.float32, name=\"keep_dropout\")\n",
    " \n",
    "# logits is the non-normalized output/activations from the last layer.\n",
    "# logits will be input for the loss function.\n",
    "# nn_model is from the import statement in the load_model function\n",
    "logits = BiRNN_model(input_tensor, tf.compat.v1.to_int64(seq_length), n_input, contexts, words_size + 1, keep_dropout)\n",
    " \n",
    "# 使用ctc loss计算损失\n",
    "avg_loss = tf.reduce_mean(ctc_ops.ctc_loss(targets, logits, seq_length))\n",
    " \n",
    "# 优化器\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(avg_loss)\n",
    " \n",
    "# 使用CTC decoder\n",
    "with tf.name_scope(\"decode\"):\n",
    "    decoded, log_prob = ctc_ops.ctc_beam_search_decoder(logits, seq_length, merge_repeated=False)\n",
    " \n",
    "# 计算编辑距离\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    distance = tf.edit_distance(tf.cast(decoded[0], tf.int32), targets)\n",
    "    # 计算label error rate (accuracy)\n",
    "    ler = tf.reduce_mean(distance, name='label_error_rate')\n",
    " \n",
    "#迭代次数\n",
    "epochs = 214\n",
    "#模型保存地址\n",
    "savedir = \"model/\"\n",
    "#如果该目录不存在，新建\n",
    "if os.path.exists(savedir) == False:\n",
    "    os.mkdir(savedir)\n",
    "\n",
    "# 生成saver\n",
    "saver = tf.compat.v1.train.Saver(max_to_keep=1)\n",
    "# 创建session\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    #初始化\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    # 没有模型的话，就重新初始化\n",
    "    kpt = tf.compat.v1.train.latest_checkpoint(savedir)\n",
    "    print(\"kpt:\", kpt)\n",
    "    startepo = 0\n",
    "    if kpt != None:\n",
    "        saver.restore(sess, kpt)\n",
    "        ind = kpt.find(\"-\")\n",
    "        startepo = int(kpt[ind + 1:])\n",
    "        print(startepo)\n",
    " \n",
    "    # 准备运行训练步骤\n",
    "    section = '\\n{0:=^40}\\n'\n",
    "    print(section.format('Run training epoch'))\n",
    " \n",
    "    train_start = time.time()\n",
    "    for epoch in range(epochs):  # 样本集迭代次数\n",
    "        epoch_start = time.time()\n",
    "        if epoch < startepo:\n",
    "            continue\n",
    " \n",
    "        print(\"epoch start:\", epoch, \"total epochs= \", epochs)\n",
    "        #######################run batch####\n",
    "        n_batches_per_epoch = int(np.ceil(len(labels) / batch_size))\n",
    "        print(\"total loop \", n_batches_per_epoch, \"in one epoch，\", batch_size, \"items in one loop\")\n",
    " \n",
    "        train_cost = 0\n",
    "        train_ler = 0\n",
    "        next_idx = 0\n",
    " \n",
    "        for batch in range(n_batches_per_epoch):  # 一次batch_size，取多少次\n",
    "            # 取数据\n",
    "            next_idx, source, source_lengths, sparse_labels = next_batch(wavs,labels,next_idx ,batch_size)\n",
    "\n",
    "            feed = {input_tensor: source, targets: sparse_labels, seq_length: source_lengths,\n",
    "                    keep_dropout: keep_dropout_rate}\n",
    " \n",
    "            # 计算 avg_loss optimizer ;\n",
    "            batch_cost, _ = sess.run([avg_loss, optimizer], feed_dict=feed)\n",
    "            train_cost = batch_cost\n",
    "            #验证模型的准确率，比较耗时，我们训练的时候全力以赴，所以这里先不跑\n",
    "            if (batch + 1) % 20 == 0:\n",
    "                print('loop:', batch, 'Train cost: ', train_cost / (batch + 1))\n",
    "                feed2 = {input_tensor: source, targets: sparse_labels, seq_length: source_lengths, keep_dropout: 1.0}\n",
    "                d, train_ler = sess.run([decoded[0], ler], feed_dict=feed2)\n",
    "                #dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "                #dense_labels = sparse_tuple_to_text(sparse_labels, words)\n",
    "            \n",
    "                counter = 0\n",
    "                print('Label err rate: ', train_ler)\n",
    "                for orig, decoded_arr in zip(dense_labels, dense_decoded):\n",
    "                    # convert to strings\n",
    "                    decoded_str = dense_to_text(decoded_arr, words)\n",
    "                    print(' file {}'.format(counter))\n",
    "                    print('Original: {}'.format(orig))\n",
    "                    print('Decoded:  {}'.format(decoded_str))\n",
    "                    counter = counter + 1\n",
    "                    break\n",
    " \n",
    "            #每训练100次保存一下模型\n",
    "            if (batch + 1) % 100 == 0:\n",
    "                saver.save(sess, savedir + \"saver.cpkt\", global_step=epoch)\n",
    "            epoch_duration = time.time() - epoch_start\n",
    "    \n",
    "            log = 'Epoch {}/{}, batch: {}, train_cost: {:.3f}, train_ler: {:.3f}, time: {:.2f} sec'\n",
    "            print(log.format(epoch, epochs, str(batch), train_cost, train_ler, epoch_duration))\n",
    " \n",
    " \n",
    "    train_duration = time.time() - train_start\n",
    "    print('Training complete, total duration: {:.2f} min'.format(train_duration / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2769aaf",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SR",
   "language": "python",
   "name": "sr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
