{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad933f7",
   "metadata": {},
   "source": [
    "# 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2603f92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:14:34.028384Z",
     "start_time": "2022-08-31T07:14:34.025361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os, time, glob, json, csv\n",
    "import librosa.display\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, Embedding, GRU, SimpleRNN, Activation, Reshape\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "#from wave import open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a14af8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed87f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:21:22.866794Z",
     "start_time": "2022-08-18T17:21:22.866785Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# k-fold-cross validation\n",
    "# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "# 10 fold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "                         \n",
    "skf = StratifiedKFold(n_split = 10, random_state = 7, shuffle = True) \n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDAITON_LOSS = []\n",
    "\n",
    "save_dir = '/saved_models/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(n),Y):\n",
    "\ttraining_data = train_data.iloc[train_index]\n",
    "\tvalidation_data = train_data.iloc[val_index]\n",
    "\t\n",
    "\ttrain_data_generator = idg.flow_from_dataframe(training_data, directory = image_dir,\n",
    "\t\t\t\t\t\t       x_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t       class_mode = \"categorical\", shuffle = True)\n",
    "\tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
    "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t\tclass_mode = \"categorical\", shuffle = True)\n",
    "\t\n",
    "\t# CREATE NEW MODEL\n",
    "\tmodel = create_new_model()\n",
    "\t# COMPILE NEW MODEL\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t      optimizer=opt,\n",
    "\t\t      metrics=['accuracy'])\n",
    "\t\n",
    "\t# CREATE CALLBACKS\n",
    "\tcheckpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "\t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1, \n",
    "\t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "\tcallbacks_list = [checkpoint]\n",
    "\t# There can be other callbacks, but just showing one because it involves the model name\n",
    "\t# This saves the best model\n",
    "\t# FIT THE MODEL\n",
    "\thistory = model.fit(train_data_generator,\n",
    "\t\t\t    epochs=num_epochs,\n",
    "\t\t\t    callbacks=callbacks_list,\n",
    "\t\t\t    validation_data=valid_data_generator)\n",
    "\t#PLOT HISTORY\n",
    "\t#\t\t:\n",
    "\t#\t\t:\n",
    "\t\n",
    "\t# LOAD BEST MODEL to evaluate the performance of the model\n",
    "\tmodel.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "\tresults = model.evaluate(valid_data_generator)\n",
    "\tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "\tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "\tVALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "\ttf.keras.backend.clear_session()\n",
    "\t\n",
    "\tfold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d40a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:34:40.399623Z",
     "start_time": "2022-07-29T09:34:39.810786Z"
    },
    "hidden": true
   },
   "source": [
    "- 寫一個確認音檔是否能正確讀取的函式，在拿到資料集之後就能馬上過濾出能用的音檔\n",
    "- 用 history 紀錄訓練資訊\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110e425",
   "metadata": {},
   "source": [
    "# 限制GPU記憶體使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c794c357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:14:36.027051Z",
     "start_time": "2022-08-31T07:14:36.019735Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    physical_gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)] \n",
    ")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6dc79",
   "metadata": {},
   "source": [
    "# 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de9c4fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:14:58.440476Z",
     "start_time": "2022-08-31T07:14:58.429590Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# https://ithelp.ithome.com.tw/articles/10195763\n",
    "\n",
    "DATA_PATH = \"./dataset/data_sr/x/\"\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "# Handy function to convert wav2mfcc\n",
    "def wav2mfcc(file_path, max_pad_len):\n",
    "    try:\n",
    "        wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "        #wave = wave[::3]\n",
    "\n",
    "        # michael added to cut my audio file\n",
    "        '''\n",
    "        i=0\n",
    "        # 訓練資料的長度\n",
    "        wav_length=5334\n",
    "        # 聲音檔過長，擷取片段\n",
    "        if len(wave) > wav_length:\n",
    "            # 尋找最大聲的點，取前後各半\n",
    "            i=np.argmax(wave)\n",
    "            if i > (wav_length):\n",
    "                wave = wave[i-int(wav_length/2):i+int(wav_length/2)]\n",
    "            else:\n",
    "                # 聲音檔過長，取前面\n",
    "                wave = wave[0:wav_length]\n",
    "        '''\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=wave, sr=sr)\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        if pad_width < 0:\n",
    "            pad_width = 0\n",
    "            mfcc = mfcc[:,:max_pad_len]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        return mfcc\n",
    "        \n",
    "    except:\n",
    "        print(file_path)\n",
    "\n",
    "def save_data_to_array(path=DATA_PATH, max_pad_len=68):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init mfcc vectors\n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        print(label+\".npy\", mfcc_vectors)\n",
    "        np.save(label + '.npy', mfcc_vectors)\n",
    "\n",
    "\n",
    "def get_train_test(split_ratio=0.8, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    \n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy', allow_pickle=True)\n",
    "    y = np.zeros(X.shape[0])\n",
    "    \n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy', allow_pickle=True)\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "    X_test, X_valid, y_test, y_valid = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state, shuffle=True)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid\n",
    "\n",
    "def prepare_dataset(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = {}\n",
    "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for wavfile in data[label]['path']:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=16000)\n",
    "            # Downsampling\n",
    "            wave = wave[::3]\n",
    "            mfcc = librosa.feature.mfcc(wave)\n",
    "            vectors.append(mfcc)\n",
    "\n",
    "        data[label]['mfcc'] = vectors\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dataset(path=DATA_PATH):\n",
    "    data = prepare_dataset(path)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for key in data:\n",
    "        for mfcc in data[key]['mfcc']:\n",
    "            dataset.append((key, mfcc))\n",
    "\n",
    "    return dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc822d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_pad_len(path):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    max_pad_len = 0\n",
    "    \n",
    "    for label in labels:\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=wave, sr=sr)\n",
    "            if mfcc.shape[1] > max_pad_len:\n",
    "                max_pad_len = mfcc.shape[1]\n",
    "                \n",
    "        print(label + \"Done\")\n",
    "        \n",
    "    return max_pad_len\n",
    "\n",
    "max_pad_len = get_max_pad_len(path)\n",
    "                \n",
    "print(max_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eec5a6e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T08:50:05.548283Z",
     "start_time": "2022-08-24T08:47:54.617500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes.npy "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.npy "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_data_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfe694fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:53:44.856366Z",
     "start_time": "2022-08-31T07:53:44.743152Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b282ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07096b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:53:48.923098Z",
     "start_time": "2022-08-31T07:53:48.919684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30101, 20, 68) (30101,)\n",
      "(3763, 20, 68) (3763,)\n",
      "(3763, 20, 68) (3763,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ea150a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:56:52.362511Z",
     "start_time": "2022-08-31T07:56:52.359578Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 20, 68, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 68, 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 20, 68, 1)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d12b32e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:56:52.692295Z",
     "start_time": "2022-08-31T07:56:52.689461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30101, 20, 68, 1) (30101,) (30101, 2)\n",
      "(3763, 20, 68, 1) (3763,)\n",
      "(3763, 20, 68, 1) (3763,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, y_train_hot.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90599b2a",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "468f2b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:53.365432Z",
     "start_time": "2022-08-31T07:54:53.180740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定義模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, \n",
    "               input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.summary()   # 顯示模型摘要資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28cf9c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:53.977082Z",
     "start_time": "2022-08-31T07:54:53.965955Z"
    }
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c77ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T06:14:33.860416Z",
     "start_time": "2022-08-26T06:14:32.792209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20, 68, 128)       256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20, 68, 128)       16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 68, 128)       0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20, 68, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20, 68, 64)        4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 87040)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2785312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,815,834\n",
      "Trainable params: 2,815,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#simple\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(20, 68, 1), activation=\"sigmoid\"))\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "baeccf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:52:32.828528Z",
     "start_time": "2022-08-31T07:52:32.712190Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c36f8f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:50.045254Z",
     "start_time": "2022-08-31T07:54:50.041711Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90aa481",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84ebd093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:56.006114Z",
     "start_time": "2022-08-31T07:54:56.002728Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_model_path(name):\n",
    "    model_path = name + '/model.h5'\n",
    "    checkpoint_path = name + '/checkpoints'\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    return model_path, checkpoint_path, checkpoint_dir, latest\n",
    "\n",
    "def train_model(model, model_name):\n",
    "    model_path, checkpoint_path, checkpoint_dir, latest = get_model_path(model_name)\n",
    "\n",
    "    model_checkpoint_callback = [ModelCheckpoint(checkpoint_path + '/weights.{epoch:02d}-{val_accuracy:.4f}.hdf5',\n",
    "                                                 monitor='val_accuracy',     \n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)]\n",
    "   \n",
    "    history = model.fit(X_train, y_train_hot, \n",
    "              epochs=100,\n",
    "             validation_data=(X_valid, y_valid_hot),\n",
    "             callbacks=model_checkpoint_callback)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccf59502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:56.264678Z",
     "start_time": "2022-08-31T07:54:56.219274Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (20, 1) but got array with shape (20, 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM_831\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m model_path, checkpoint_path, checkpoint_dir, latest \u001b[38;5;241m=\u001b[39m get_model_path(model_name)\n\u001b[1;32m     15\u001b[0m model_checkpoint_callback \u001b[38;5;241m=\u001b[39m [ModelCheckpoint(checkpoint_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/weights.\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{val_accuracy:.4f}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                              monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,     \n\u001b[1;32m     17\u001b[0m                                              mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                              save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history, model\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:1150\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_generator(\n\u001b[1;32m   1134\u001b[0m         x,\n\u001b[1;32m   1135\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   1147\u001b[0m         initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch)\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;66;03m# Case 2: Symbolic tensors or Numpy array-like.\u001b[39;00m\n\u001b[0;32m-> 1150\u001b[0m x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_user_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# Prepare validation data.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m do_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:574\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    571\u001b[0m     feed_input_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_input_shapes\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_graph_network:\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training_utils.py:141\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m dim, ref_dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_shape, shape):\n\u001b[1;32m    140\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m ref_dim \u001b[38;5;241m!=\u001b[39m dim \u001b[38;5;129;01mand\u001b[39;00m ref_dim:\n\u001b[0;32m--> 141\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError when checking \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m exception_prefix \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    143\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m names[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    144\u001b[0m                         \u001b[38;5;28mstr\u001b[39m(shape) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got array with shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    145\u001b[0m                         \u001b[38;5;28mstr\u001b[39m(data_shape))\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (20, 1) but got array with shape (20, 68)"
     ]
    }
   ],
   "source": [
    "history, model = train_model(model, 'LSTM_831')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74477b0",
   "metadata": {},
   "source": [
    "# 模型評估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06485d4f",
   "metadata": {},
   "source": [
    "- 測試資料集的 loss, accuracy, recall, precision, f1, mse, mae\n",
    "- 訓練時的 loss, accuracy\n",
    "- 驗證資料的 loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a718f2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:44:32.590283Z",
     "start_time": "2022-08-31T07:44:32.584000Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))\n",
    "\n",
    "def evaluate_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                 optimizer=keras.optimizers.Adadelta(),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # loss, acc\n",
    "    loss_train, accuracy_train = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "    loss_val, accuracy_val = model.evaluate(X_valid, y_valid_hot, verbose=0)\n",
    "    loss_test, accuracy_test = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "    print(\"訓練\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_train, accuracy_train))\n",
    "    print(\"驗證\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_val, accuracy_val))\n",
    "    print(\"測試\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_test, accuracy_test))\n",
    "    \n",
    "    # test precision, recall, f1\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred , average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred , average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "    print(\"Precision: %0.4f, Recall: %0.4f, F1: %0.4f\" %(precision, recall, f1))\n",
    "    \n",
    "    # test mse, mae\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    mse, mae = model.evaluate(X_test, y_test_hot)\n",
    "    print(\"MSE: %0.4f, MAE: %0.4f\" %(mse, mae))\n",
    "    \n",
    "    # test classification report\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    classifi_report = classification_report(y_test, y_pred)\n",
    "    print(classifi_report)\n",
    "    \n",
    "    # loss, accuracy, by epoch\n",
    "    plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48186e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:44:37.544325Z",
     "start_time": "2022-08-31T07:44:32.999488Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20, 68, 128)       256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20, 68, 128)       16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 68, 128)       0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20, 68, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20, 68, 64)        4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 87040)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2785312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,815,834\n",
      "Trainable params: 2,815,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "訓練\n",
      "Loss: 0.6931, Accuracy: 0.5014\n",
      "驗證\n",
      "Loss: 0.6933, Accuracy: 0.4916\n",
      "測試\n",
      "Loss: 0.6932, Accuracy: 0.4969\n",
      "Precision: 0.2485, Recall: 0.5000, F1: 0.3320\n",
      " 672/3763 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3763/3763 [==============================] - 0s 92us/step\n",
      "MSE: 0.2501, MAE: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.66      1870\n",
      "         1.0       0.00      0.00      0.00      1893\n",
      "\n",
      "    accuracy                           0.50      3763\n",
      "   macro avg       0.25      0.50      0.33      3763\n",
      "weighted avg       0.25      0.50      0.33      3763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_path = '2class_5:5_rnn/model.h5'\n",
    "#model_path = '2class_5:5_bilstm/model.h5'\n",
    "#model_path = '2class_origin_rnn/model.h5'\n",
    "#model_path = '2class_origin_bilstm/model.h5'\n",
    "\n",
    "#model_path = 'D7_819_notearlystop/model.h5'\n",
    "model_path = 'D7_826_/model.h5'\n",
    "evaluate_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cf901",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1546ed4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:16:52.083820Z",
     "start_time": "2022-08-18T17:16:52.080161Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorboard 紀錄訓練時的指標\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "    # model path\n",
    "def get_model_path(name):\n",
    "    model_path = name + '/model.h5'\n",
    "    checkpoint_path = name + '/checkpoints'\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    return model_path, checkpoint_path, checkpoint_dir, latest\n",
    "\n",
    "def train_model(model, model_name):\n",
    "    model_path, checkpoint_path, checkpoint_dir, latest = get_model_path(model_name)\n",
    "    \n",
    "    \n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, monitor = 'val_accuracy')]\n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid), callbacks=my_callbacks)\n",
    "    '''\n",
    "    ck_callback = ModelCheckpoint(checkpoint_path + '/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n",
    "                                                 monitor='val_accuracy',     \n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n",
    "    tb_callback = TensorBoard(log_dir=model_name + '/logs', profile_batch=0)\n",
    "   \n",
    "    history = model.fit(X_train, y_train, \n",
    "              batch_size=32, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[Metrics(valid_data=(X_valid, y_valid)),\n",
    "                         ck_callback,\n",
    "                         tb_callback])\n",
    "     '''\n",
    "    \n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95357e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:04:46.972174Z",
     "start_time": "2022-07-29T01:46:44.171104Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#2class 5:5 BiLSTM M2\n",
    "model_path = '2class_5:5_bilstm_m2/model.h5'\n",
    "checkpoint_path = './2class_5:5_bilstm_m2/checkpoints'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "    # 模型儲存\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "\n",
    "# 按照 accuracy 保存模型\n",
    "ck_callback = ModelCheckpoint('./2class_5:5_bilstm_m2/checkpoints/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n",
    "                                                 monitor='accuracy',        # 改成 accuracy\n",
    "                                                 mode='max', verbose=2,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "tb_callback = TensorBoard(log_dir='./2class_5:5_bilstm_m2/logs', profile_batch=0)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=32, epochs=100,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks=[Metrics(valid_data=(X_valid, y_valid)),\n",
    "                     ck_callback,\n",
    "                     tb_callback])\n",
    "\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df03134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:42:46.743336Z",
     "start_time": "2022-07-29T09:42:46.285722Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del csv_file, csvfile\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2af50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5:5\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "x_train = x.reshape(x.shape[0], (x.shape[1]*x.shape[2]))\n",
    "\n",
    "X_train_under, y_train_under = undersample.fit_resample(x_train, y)\n",
    "X_train_under = X_train_under.reshape((X_train_under.shape[0], 108, 494))\n",
    "\n",
    "unique, counts = np.unique(y_train_under, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce349f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:25.414520Z",
     "start_time": "2022-07-31T13:58:25.408978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9da3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:43.621255Z",
     "start_time": "2022-07-31T13:58:43.614891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78530ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:52.262824Z",
     "start_time": "2022-07-31T13:58:52.259644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_valid, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb86996",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 將 label為有與 label 為無的檔案名稱取出\n",
    "with open('file_yes.txt', 'w') as f:\n",
    "    for file in file_yes:\n",
    "        f.write(f\"{file}\\n\")\n",
    "\n",
    "with open('file_no.txt', 'w') as f:\n",
    "    for file in file_no:\n",
    "        f.write(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d8e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T14:36:19.383822Z",
     "start_time": "2022-07-31T14:36:19.376741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('audio_filename.txt', 'w') as f:\n",
    "    for file in files:\n",
    "        f.write(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bab4cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988eed9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('audio_test.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in d.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dadd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T06:36:06.285998Z",
     "start_time": "2022-07-15T06:36:06.283837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae606f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:54:28.629073Z",
     "start_time": "2022-07-15T08:54:28.605697Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(audio_reshape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b466f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T09:00:12.420670Z",
     "start_time": "2022-07-15T09:00:11.596440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(x,y, how=\"right\", left_on=\"檔名\", right_on=\"檔名\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e9b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:40:24.457275Z",
     "start_time": "2022-07-16T05:40:24.265903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_reshape = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "#files.remove(1618243237)\n",
    "#files.remove(1618243179)\n",
    "#files.remove(1618243233)\n",
    "'''              \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45573cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:22:41.312525Z",
     "start_time": "2022-07-15T07:19:24.118302Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "audio_reshape.astype(np.float32)\n",
    "print(audio_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75774aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:45:00.617452Z",
     "start_time": "2022-07-15T08:44:32.923229Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "                \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd45fdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:14:39.842637Z",
     "start_time": "2022-07-31T16:14:37.863787Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#files\n",
    "\n",
    "import os\n",
    "# 取得 label 檔名與內容\n",
    "def get_labels_and_texts(label_path):\n",
    "    labels = []\n",
    "    labels_path = []\n",
    "    label_texts = []\n",
    "    for(dirpath, dirnames, filenames) in os.walk(label_path):\n",
    "        for filename in filenames:\n",
    "            \n",
    "            #取得 label 的完整路徑，後面進行讀檔\n",
    "            filename_path = os.path.join(dirpath, filename)\n",
    "            labels_path.append(filename_path)\n",
    "\n",
    "            #取得 label的檔名，後面對應到音檔\n",
    "            \n",
    "            try:\n",
    "                index = filename.index(\"_\")\n",
    "            except ValueError:\n",
    "                index = filename.index(\".\")\n",
    "\n",
    "            filename = filename[:index]\n",
    "            \n",
    "            labels.append(filename)\n",
    "    for label_file in labels_path:\n",
    "        #讀取 label 檔，並將 command 以 one-hot encoding 方式改寫 label\n",
    "        try:\n",
    "            with open(label_file) as fd:\n",
    "                data = json.load(fd)\n",
    "                a = 0\n",
    "                #b = 0\n",
    "                #c = 0\n",
    "                #d = 0\n",
    "                if data['command'] == 'Not Activated':\n",
    "                    a = '0'\n",
    "                else:\n",
    "                    a = '1'\n",
    "                data = [a]\n",
    "                label_texts.append(data)\n",
    "                fd.close()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return labels, label_texts\n",
    "\n",
    "label_path = 'dataset/data_sr/y_data'\n",
    "labels, label_texts = get_labels_and_texts(label_path)\n",
    "\n",
    "print(labels[0], label_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb6cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T15:47:34.083089Z",
     "start_time": "2022-07-31T15:47:25.129847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/data_sr/y_data'     \n",
    "\n",
    "#獲取該目錄下所有文件，存入列表中\n",
    "fileList = os.listdir ( path )\n",
    "\n",
    "n = 0\n",
    "for(dirpath, dirnames, filenames) in os.walk(label_path):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        #取得 label 的完整路徑，後面進行讀檔\n",
    "        oldname = os.path.join(dirpath, filename)\n",
    "        \n",
    "        try:\n",
    "            index = filename.index(\"_\")\n",
    "        except ValueError:\n",
    "            index = filename.index(\".\")\n",
    "\n",
    "        filename = filename[:index]\n",
    "        \n",
    "        #print(filename)\n",
    "\n",
    "        #設置新文件名\n",
    "        newname = path + os.sep + filename + '.json'\n",
    "        print(oldname)\n",
    "        print(newname)\n",
    "        os . rename ( oldname , newname ) #用os模塊中的rename方法對文件改名print ( oldname , '======>' , newname ) \n",
    "        n += 1\n",
    "        #if n > 10: break\n",
    "\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b26db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T15:12:49.787934Z",
     "start_time": "2022-07-14T15:12:49.782839Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#將 檔名與 label 寫入 csv 檔\n",
    "\n",
    "i = 0\n",
    "for label_text in label_texts:\n",
    "    label_text.insert(0, labels[i])\n",
    "    i+=1\n",
    "\n",
    "with open('dataset/data_sr/label_sample_twoclass.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['檔名','指令'])\n",
    "    \n",
    "    for label_text in label_texts:\n",
    "        writer.writerow(label_text)\n",
    "print(label_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a295c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:00:27.820019Z",
     "start_time": "2022-07-04T18:00:09.937313Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 將 檔名與特徵寫入 csv 檔\n",
    "\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "\n",
    "a_list = list(audio)\n",
    "i = 0\n",
    "b = {}\n",
    "c = []\n",
    "for a in a_list:\n",
    "    b = {\"檔名\":aa[i],\"特徵\": a}\n",
    "    c.append(b)\n",
    "    i+=1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open(audio_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col)\n",
    "        writer.writeheader()\n",
    "        #writer.writerow(['檔名','特徵'])\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7b43f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3D Numpy array to a CSV file\n",
    "# reshaping the array from 3D matrice to 2D matrice.\n",
    "arrReshaped = arr.reshape(arr.shape[0], -1)\n",
    "# saving reshaped array to file.\n",
    "np.savetxt(filename, arrReshaped)\n",
    "# retrieving data from file.\n",
    "loadedArr = np.loadtxt(filename)\n",
    "# This loadedArr is a 2D array, therefore we need to convert it to the original array shape.\n",
    "# reshaping to get original matrice with original shape.\n",
    "loadedOriginal = loadedArr.reshape(loadedArr.shape[0], loadedArr.shape[1] // arr.shape[2], arr.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a2fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T15:51:20.934271Z",
     "start_time": "2022-07-04T15:51:20.910371Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#load label csv into pd to preview data\n",
    "labels = pd.read_csv(label_csv_path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce388b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:01:04.486671Z",
     "start_time": "2022-07-04T18:01:04.275761Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#load audio csv into pd to preview data\n",
    "\n",
    "#audios = pd.read_csv(audio_csv_path)\n",
    "#audios\n",
    "\n",
    "\n",
    "with open(audio_csv_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    examples = list(reader)\n",
    "del examples[0]\n",
    "#print(examples)\n",
    "\n",
    "nwexamples = []\n",
    "for row in examples:\n",
    "    nwrow = []\n",
    "    for r in row:\n",
    "        #could not convert string to float:\n",
    "        r = np.array(r, dtype=np.float32)\n",
    "        nwrow.append(r)\n",
    "    nwexamples.append(nwrow)\n",
    "print(nwexamples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e50fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T21:42:15.621455Z",
     "start_time": "2022-07-14T21:33:46.140708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m,n,r = audio.shape\n",
    "out_arr = np.column_stack((np.repeat(np.arange(m),n),audio.reshape(m*n,-1)))\n",
    "out_df = pd.DataFrame(out_arr)\n",
    "\n",
    "X = out_df[out_df.columns[:]].values   #dead kernel\n",
    "\n",
    "\n",
    "#np.savetxt('audio.csv', audio, delimiter=',')    # can't save filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:08:43.712458Z",
     "start_time": "2022-07-14T11:48:40.051336Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using python_speech_features to extract mfcc feartures\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# directory where we your .wav files are\n",
    "directoryName = \"dataset/data_sr/data\" # put your own directory here\n",
    "# directory to put our results in, you can change the name if you like\n",
    "resultsDirectory = 'dataset/data_sr/audio_sample'\n",
    "\n",
    "# make a new folder in this directory to save our results in\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "for filename in os.listdir(directoryName):\n",
    "    if filename.endswith('.wav'): # only get MFCCs from .wavs\n",
    "        # read in our file\n",
    "        \n",
    "        try:\n",
    "            (rate,sig) = wav.read(directoryName + \"/\" +filename)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # get mfcc\n",
    "        mfcc_feat = mfcc(sig,rate)\n",
    "\n",
    "        # get filterbank energies\n",
    "        fbank_feat = logfbank(sig,rate)\n",
    "        \n",
    "        # create a file to save our results in\n",
    "       \n",
    "        outputFile = resultsDirectory + \"/\" + os.path.splitext(filename)[0] + \".csv\"\n",
    "        file = open(outputFile, 'w+') # make file/over write existing file\n",
    "        numpy.savetxt(file, fbank_feat, delimiter=\",\") #save MFCCs as .csv\n",
    "        file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a1da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:06.246517Z",
     "start_time": "2022-07-14T12:12:54.273516Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read all audio sample csv\n",
    "audio_csvs_path = 'dataset/data_sr/audio_sample'\n",
    "csv = glob.glob(audio_csvs_path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "for filename in csv:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9880eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:56.187532Z",
     "start_time": "2022-07-14T12:19:56.118386Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine all csvs into one\n",
    "def return_contents(file_name):\n",
    "    with open(file_name) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        return list(reader)\n",
    "\n",
    "all_files = os.listdir('dataset/data_sr/audio_sample')\n",
    "combined_output = []\n",
    "\n",
    "for file in all_files:\n",
    "    data = return_contents('dataset/data_sr/audio_sample/{}'.format(file))\n",
    "    for row in data:\n",
    "        combined_output.extend(row)\n",
    "\n",
    "with open('dataset/data_sr/audio_sample_2.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3d12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:52:44.864601Z",
     "start_time": "2022-07-04T07:52:44.114911Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using librosa to extract mfcc features\n",
    "x, sr = librosa.load(wavs[0])\n",
    "\n",
    "#Plot the signal:\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)\n",
    "# Zooming in\n",
    "n0 = 9000\n",
    "n1 = 9100\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(x[n0:n1])\n",
    "plt.grid()\n",
    "\n",
    "fs=10\n",
    "mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "\n",
    "print(mfccs.shape)\n",
    "#Displaying  the MFCCs:\n",
    "plt.figure(figsize=(15, 7))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558f72d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_reshaped = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "np.savetxt(\"audio.csv\", audio_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec3955",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d263b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "d = dict()\n",
    "for i in range(len(audio)):\n",
    "    d[files[i]] = audio[i]\n",
    "print(len(d))\n",
    "\n",
    "### Store dictionary d into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28e21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:05:48.906189Z",
     "start_time": "2022-07-15T02:03:31.977629Z"
    },
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_path = 'dataset/data_sr/data'\n",
    "\n",
    "# 將 flac 音檔轉成 wav 音檔\n",
    "def get_flacs(audio_path):\n",
    "    flacs = []\n",
    "    flac_filename = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.flac'):\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                index = filename.index(\".\")\n",
    "                    \n",
    "                filename = filename[:index]\n",
    "                flac_filename.append(filename)\n",
    "                \n",
    "                flacs.append(filename_path)\n",
    "    return flacs, flac_filename\n",
    "\n",
    "flacs,flac_filename = get_flacs(audio_path)\n",
    "\n",
    "i = 0\n",
    "for flac in flacs:\n",
    "    try:\n",
    "        audio, sr = sf.read(flac)\n",
    "    except RuntimeError:\n",
    "        print(flac)\n",
    "    sf.write(audio_path+'/'+flac_filename[i]+'.wav', audio, sr, 'PCM_16')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524d662",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df1[\"有指令\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8cd53",
   "metadata": {},
   "source": [
    "# 分出兩個類別的音檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:36:57.603159Z",
     "start_time": "2022-07-31T16:36:57.533689Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_filename = []\n",
    "audio_path = 'dataset/data_sr/x_all'\n",
    "\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                audio_filename.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ca6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:36:58.429804Z",
     "start_time": "2022-07-31T16:36:58.422324Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(audio_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea782be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:34:38.504798Z",
     "start_time": "2022-07-31T16:34:35.084160Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_str(var):\n",
    "    return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]\n",
    "\n",
    "file_yes = []\n",
    "file_no = []\n",
    "\n",
    "for index, row in y.iterrows():\n",
    "    file = to_str(row['檔名'])\n",
    "    if (row['指令']==0):\n",
    "        file_no.append(file)\n",
    "    else:\n",
    "        file_yes.append(file)\n",
    "    #print(row['檔名'], row['指令'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e3e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:12.782691Z",
     "start_time": "2022-07-31T16:37:12.777892Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(file_yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f31f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:09.473818Z",
     "start_time": "2022-07-31T16:37:09.455383Z"
    }
   },
   "outputs": [],
   "source": [
    "setA = set(audio_filename)\n",
    "setB = set(file_yes)\n",
    "setC = set(file_no)\n",
    "\n",
    "setYes = setA & setB\n",
    "setNo = setA & setC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:09.957193Z",
     "start_time": "2022-07-31T16:37:09.954754Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(setYes), len(setNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a29e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:38:05.464769Z",
     "start_time": "2022-07-31T16:38:05.462945Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "file_source = 'dataset/data_sr/x_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79940c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:38:53.483581Z",
     "start_time": "2022-07-31T16:38:53.115729Z"
    }
   },
   "outputs": [],
   "source": [
    "file_destination = 'dataset/data_sr/x/yes'\n",
    "\n",
    "for i in setYes:\n",
    "        try:\n",
    "            shutil.move(file_source + i + '.wav', file_destination)\n",
    "        except:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e076ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:41:23.718186Z",
     "start_time": "2022-07-31T16:41:22.408650Z"
    }
   },
   "outputs": [],
   "source": [
    "file_destination = 'dataset/data_sr/x/no/'\n",
    "\n",
    "for i in setNo:\n",
    "        try:\n",
    "            shutil.move(file_source + i + '.wav', file_destination)\n",
    "        except:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296f43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SR",
   "language": "python",
   "name": "sr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 470.844,
   "position": {
    "height": "503.837px",
    "left": "117.998px",
    "right": "20px",
    "top": "25.9965px",
    "width": "567.995px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
