{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad933f7",
   "metadata": {},
   "source": [
    "# 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2603f92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:07.173059Z",
     "start_time": "2022-08-31T12:51:05.613131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os, time, glob, json, csv\n",
    "import librosa.display\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, Embedding, GRU, SimpleRNN, Activation, Reshape\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "#from wave import open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a14af8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# To-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed87f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:21:22.866794Z",
     "start_time": "2022-08-18T17:21:22.866785Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# k-fold-cross validation\n",
    "# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "# 10 fold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "                         \n",
    "skf = StratifiedKFold(n_split = 10, random_state = 7, shuffle = True) \n",
    "\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDAITON_LOSS = []\n",
    "\n",
    "save_dir = '/saved_models/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(n),Y):\n",
    "\ttraining_data = train_data.iloc[train_index]\n",
    "\tvalidation_data = train_data.iloc[val_index]\n",
    "\t\n",
    "\ttrain_data_generator = idg.flow_from_dataframe(training_data, directory = image_dir,\n",
    "\t\t\t\t\t\t       x_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t       class_mode = \"categorical\", shuffle = True)\n",
    "\tvalid_data_generator  = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
    "\t\t\t\t\t\t\tx_col = \"filename\", y_col = \"label\",\n",
    "\t\t\t\t\t\t\tclass_mode = \"categorical\", shuffle = True)\n",
    "\t\n",
    "\t# CREATE NEW MODEL\n",
    "\tmodel = create_new_model()\n",
    "\t# COMPILE NEW MODEL\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t      optimizer=opt,\n",
    "\t\t      metrics=['accuracy'])\n",
    "\t\n",
    "\t# CREATE CALLBACKS\n",
    "\tcheckpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "\t\t\t\t\t\t\tmonitor='val_accuracy', verbose=1, \n",
    "\t\t\t\t\t\t\tsave_best_only=True, mode='max')\n",
    "\tcallbacks_list = [checkpoint]\n",
    "\t# There can be other callbacks, but just showing one because it involves the model name\n",
    "\t# This saves the best model\n",
    "\t# FIT THE MODEL\n",
    "\thistory = model.fit(train_data_generator,\n",
    "\t\t\t    epochs=num_epochs,\n",
    "\t\t\t    callbacks=callbacks_list,\n",
    "\t\t\t    validation_data=valid_data_generator)\n",
    "\t#PLOT HISTORY\n",
    "\t#\t\t:\n",
    "\t#\t\t:\n",
    "\t\n",
    "\t# LOAD BEST MODEL to evaluate the performance of the model\n",
    "\tmodel.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "\tresults = model.evaluate(valid_data_generator)\n",
    "\tresults = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "\tVALIDATION_ACCURACY.append(results['accuracy'])\n",
    "\tVALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "\ttf.keras.backend.clear_session()\n",
    "\t\n",
    "\tfold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d40a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:34:40.399623Z",
     "start_time": "2022-07-29T09:34:39.810786Z"
    },
    "hidden": true
   },
   "source": [
    "- 寫一個確認音檔是否能正確讀取的函式，在拿到資料集之後就能馬上過濾出能用的音檔\n",
    "- 用 history 紀錄訓練資訊\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110e425",
   "metadata": {},
   "source": [
    "# 限制GPU記憶體使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c794c357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:08.910713Z",
     "start_time": "2022-08-31T12:51:08.693012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:51:08.697785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-31 20:51:08.719934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.720024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-08-31 20:51:08.720167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:51:08.721466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:51:08.722677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:51:08.722884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:51:08.724274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:51:08.724989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:51:08.727897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:51:08.727986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.728116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.728180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-08-31 20:51:08.729485: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-08-31 20:51:08.752569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2799925000 Hz\n",
      "2022-08-31 20:51:08.753438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564734fc8880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-31 20:51:08.753450: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-31 20:51:08.753715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.753793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-08-31 20:51:08.753821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:51:08.753835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:51:08.753848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:51:08.753861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:51:08.753873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:51:08.753885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:51:08.753898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:51:08.753942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.754034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.754088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-08-31 20:51:08.754116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:51:08.905087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-31 20:51:08.905104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-08-31 20:51:08.905111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-08-31 20:51:08.905257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.905448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.905534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:51:08.905602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2022-08-31 20:51:08.906803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564734f4c3a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-31 20:51:08.906812: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n"
     ]
    }
   ],
   "source": [
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    physical_gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)] \n",
    ")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6dc79",
   "metadata": {},
   "source": [
    "# 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9c4fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:21.626875Z",
     "start_time": "2022-08-31T12:51:21.617500Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# https://ithelp.ithome.com.tw/articles/10195763\n",
    "\n",
    "DATA_PATH = \"./dataset/data_sr/x/\"\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "# Handy function to convert wav2mfcc\n",
    "def wav2mfcc(file_path, max_pad_len):\n",
    "    try:\n",
    "        wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "        #wave = wave[::3]\n",
    "\n",
    "        # michael added to cut my audio file\n",
    "        '''\n",
    "        i=0\n",
    "        # 訓練資料的長度\n",
    "        wav_length=5334\n",
    "        # 聲音檔過長，擷取片段\n",
    "        if len(wave) > wav_length:\n",
    "            # 尋找最大聲的點，取前後各半\n",
    "            i=np.argmax(wave)\n",
    "            if i > (wav_length):\n",
    "                wave = wave[i-int(wav_length/2):i+int(wav_length/2)]\n",
    "            else:\n",
    "                # 聲音檔過長，取前面\n",
    "                wave = wave[0:wav_length]\n",
    "        '''\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=wave, sr=sr)\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        if pad_width < 0:\n",
    "            pad_width = 0\n",
    "            mfcc = mfcc[:,:max_pad_len]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        return mfcc\n",
    "        \n",
    "    except:\n",
    "        print(file_path)\n",
    "\n",
    "def save_data_to_array(path=DATA_PATH, max_pad_len=68):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init mfcc vectors\n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            mfcc = wav2mfcc(wavfile, max_pad_len=max_pad_len)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        print(label+\".npy\", mfcc_vectors)\n",
    "        np.save(label + '.npy', mfcc_vectors)\n",
    "\n",
    "\n",
    "def get_train_test(split_ratio=0.8, random_state=42):\n",
    "    # Get available labels\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    \n",
    "    # Getting first arrays\n",
    "    X = np.load(labels[0] + '.npy', allow_pickle=True)\n",
    "    y = np.zeros(X.shape[0])\n",
    "    \n",
    "\n",
    "    # Append all of the dataset into one single array, same goes for y\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy', allow_pickle=True)\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "    X_test, X_valid, y_test, y_valid = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state, shuffle=True)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid\n",
    "\n",
    "def prepare_dataset(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = {}\n",
    "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for wavfile in data[label]['path']:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=16000)\n",
    "            # Downsampling\n",
    "            wave = wave[::3]\n",
    "            mfcc = librosa.feature.mfcc(wave)\n",
    "            vectors.append(mfcc)\n",
    "\n",
    "        data[label]['mfcc'] = vectors\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dataset(path=DATA_PATH):\n",
    "    data = prepare_dataset(path)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for key in data:\n",
    "        for mfcc in data[key]['mfcc']:\n",
    "            dataset.append((key, mfcc))\n",
    "\n",
    "    return dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc822d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_pad_len(path):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    max_pad_len = 0\n",
    "    \n",
    "    for label in labels:\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in wavfiles:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=wave, sr=sr)\n",
    "            if mfcc.shape[1] > max_pad_len:\n",
    "                max_pad_len = mfcc.shape[1]\n",
    "                \n",
    "        print(label + \"Done\")\n",
    "        \n",
    "    return max_pad_len\n",
    "\n",
    "max_pad_len = get_max_pad_len(path)\n",
    "                \n",
    "print(max_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eec5a6e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T08:50:05.548283Z",
     "start_time": "2022-08-24T08:47:54.617500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes.npy "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.npy "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_data_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe694fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:23.014324Z",
     "start_time": "2022-08-31T12:51:22.900040Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b282ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07096b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:23.921743Z",
     "start_time": "2022-08-31T12:51:23.919119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30101, 20, 68) (30101,)\n",
      "(3763, 20, 68) (3763,)\n",
      "(3763, 20, 68) (3763,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea150a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:24.365993Z",
     "start_time": "2022-08-31T12:51:24.353695Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 20, 68, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 68, 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 20, 68, 1)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d12b32e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:24.732137Z",
     "start_time": "2022-08-31T12:51:24.729161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30101, 20, 68, 1) (30101,) (30101, 2)\n",
      "(3763, 20, 68, 1) (3763,)\n",
      "(3763, 20, 68, 1) (3763,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, y_train_hot.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90599b2a",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "468f2b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:53.365432Z",
     "start_time": "2022-08-31T07:54:53.180740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定義模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, \n",
    "               input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.summary()   # 顯示模型摘要資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28cf9c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:53.977082Z",
     "start_time": "2022-08-31T07:54:53.965955Z"
    }
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c77ee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-26T06:14:33.860416Z",
     "start_time": "2022-08-26T06:14:32.792209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20, 68, 128)       256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20, 68, 128)       16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 68, 128)       0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20, 68, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20, 68, 64)        4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 68, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 87040)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2785312   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,815,834\n",
      "Trainable params: 2,815,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#simple\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(20, 68, 1), activation=\"sigmoid\"))\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "baeccf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:52:32.828528Z",
     "start_time": "2022-08-31T07:52:32.712190Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c36f8f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:50.045254Z",
     "start_time": "2022-08-31T07:54:50.041711Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90aa481",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84ebd093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:56.006114Z",
     "start_time": "2022-08-31T07:54:56.002728Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_model_path(name):\n",
    "    model_path = name + '/model.h5'\n",
    "    checkpoint_path = name + '/checkpoints'\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    return model_path, checkpoint_path, checkpoint_dir, latest\n",
    "\n",
    "def train_model(model, model_name):\n",
    "    model_path, checkpoint_path, checkpoint_dir, latest = get_model_path(model_name)\n",
    "\n",
    "    model_checkpoint_callback = [ModelCheckpoint(checkpoint_path + '/weights.{epoch:02d}-{val_accuracy:.4f}.hdf5',\n",
    "                                                 monitor='val_accuracy',     \n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)]\n",
    "   \n",
    "    history = model.fit(X_train, y_train_hot, \n",
    "              epochs=100,\n",
    "             validation_data=(X_valid, y_valid_hot),\n",
    "             callbacks=model_checkpoint_callback)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccf59502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T07:54:56.264678Z",
     "start_time": "2022-08-31T07:54:56.219274Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (20, 1) but got array with shape (20, 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history, model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLSTM_831\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m model_path, checkpoint_path, checkpoint_dir, latest \u001b[38;5;241m=\u001b[39m get_model_path(model_name)\n\u001b[1;32m     15\u001b[0m model_checkpoint_callback \u001b[38;5;241m=\u001b[39m [ModelCheckpoint(checkpoint_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/weights.\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{val_accuracy:.4f}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                              monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,     \n\u001b[1;32m     17\u001b[0m                                              mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                              save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history, model\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:1150\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_generator(\n\u001b[1;32m   1134\u001b[0m         x,\n\u001b[1;32m   1135\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   1147\u001b[0m         initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch)\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;66;03m# Case 2: Symbolic tensors or Numpy array-like.\u001b[39;00m\n\u001b[0;32m-> 1150\u001b[0m x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_user_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# Prepare validation data.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m do_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:574\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    571\u001b[0m     feed_input_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_input_shapes\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_graph_network:\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training_utils.py:141\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m dim, ref_dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_shape, shape):\n\u001b[1;32m    140\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m ref_dim \u001b[38;5;241m!=\u001b[39m dim \u001b[38;5;129;01mand\u001b[39;00m ref_dim:\n\u001b[0;32m--> 141\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError when checking \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m exception_prefix \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    143\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m names[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    144\u001b[0m                         \u001b[38;5;28mstr\u001b[39m(shape) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got array with shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    145\u001b[0m                         \u001b[38;5;28mstr\u001b[39m(data_shape))\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (20, 1) but got array with shape (20, 68)"
     ]
    }
   ],
   "source": [
    "history, model = train_model(model, 'LSTM_831')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74477b0",
   "metadata": {},
   "source": [
    "# 模型評估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06485d4f",
   "metadata": {},
   "source": [
    "- 測試資料集的 loss, accuracy, recall, precision, f1, mse, mae\n",
    "- 訓練時的 loss, accuracy\n",
    "- 驗證資料的 loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a718f2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:31.193851Z",
     "start_time": "2022-08-31T12:51:31.047045Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))\n",
    "\n",
    "def evaluate_model(model_path):\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                 optimizer=keras.optimizers.Adadelta(),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    # loss, acc\n",
    "    loss_train, accuracy_train = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "    loss_val, accuracy_val = model.evaluate(X_valid, y_valid_hot, verbose=0)\n",
    "    loss_test, accuracy_test = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "    print(\"訓練\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_train, accuracy_train))\n",
    "    print(\"驗證\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_val, accuracy_val))\n",
    "    print(\"測試\")\n",
    "    print(\"Loss: %0.4f, Accuracy: %0.4f\" %(loss_test, accuracy_test))\n",
    "    \n",
    "    # test precision, recall, f1\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred , average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred , average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "    print(\"Precision: %0.4f, Recall: %0.4f, F1: %0.4f\" %(precision, recall, f1))\n",
    "    \n",
    "    # test mse, mae\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    mse, mae = model.evaluate(X_test, y_test_hot)\n",
    "    print(\"MSE: %0.4f, MAE: %0.4f\" %(mse, mae))\n",
    "    \n",
    "    # test classification report\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    classifi_report = classification_report(y_test, y_pred)\n",
    "    print(classifi_report)\n",
    "    \n",
    "    # loss, accuracy, by epoch\n",
    "    #plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48186e35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-31T12:51:32.767046Z",
     "start_time": "2022-08-31T12:51:32.613592Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 8 layers into a model with 0 layers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model_path = '2class_5:5_rnn/model.h5'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model_path = '2class_5:5_bilstm/model.h5'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model_path = '2class_origin_rnn/model.h5'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model_path = '2class_origin_bilstm/model.h5'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#model_path = 'D7_819_notearlystop/model.h5'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m831_2/model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model_path):\n\u001b[0;32m---> 16\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy,\n\u001b[1;32m     19\u001b[0m                  optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdadelta(),\n\u001b[1;32m     20\u001b[0m                  metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/saving.py:492\u001b[0m, in \u001b[0;36mallow_read_from_gcs.<locals>.load_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(tmp_filepath)\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/saving.py:584\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m H5Dict\u001b[38;5;241m.\u001b[39mis_supported_type(filepath):\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m H5Dict(filepath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5dict:\n\u001b[0;32m--> 584\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m callable(filepath\u001b[38;5;241m.\u001b[39mwrite):\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_function\u001b[39m(h5file):\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/saving.py:305\u001b[0m, in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    303\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are trying to load a weight file\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    306\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m containing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m layers into a model with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m layers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    307\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(layer_names), \u001b[38;5;28mlen\u001b[39m(filtered_layers))\n\u001b[1;32m    308\u001b[0m                      )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 8 layers into a model with 0 layers"
     ]
    }
   ],
   "source": [
    "#model_path = '2class_5:5_rnn/model.h5'\n",
    "#model_path = '2class_5:5_bilstm/model.h5'\n",
    "#model_path = '2class_origin_rnn/model.h5'\n",
    "#model_path = '2class_origin_bilstm/model.h5'\n",
    "\n",
    "#model_path = 'D7_819_notearlystop/model.h5'\n",
    "model_path = '831_2/model.h5'\n",
    "evaluate_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165cf901",
   "metadata": {
    "heading_collapsed": true,
    "hide_input": false
   },
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1546ed4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T17:16:52.083820Z",
     "start_time": "2022-08-18T17:16:52.080161Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tensorboard 紀錄訓練時的指標\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "    # model path\n",
    "def get_model_path(name):\n",
    "    model_path = name + '/model.h5'\n",
    "    checkpoint_path = name + '/checkpoints'\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    return model_path, checkpoint_path, checkpoint_dir, latest\n",
    "\n",
    "def train_model(model, model_name):\n",
    "    model_path, checkpoint_path, checkpoint_dir, latest = get_model_path(model_name)\n",
    "    \n",
    "    \n",
    "    my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=3, monitor = 'val_accuracy')]\n",
    "    history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid), callbacks=my_callbacks)\n",
    "    '''\n",
    "    ck_callback = ModelCheckpoint(checkpoint_path + '/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n",
    "                                                 monitor='val_accuracy',     \n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n",
    "    tb_callback = TensorBoard(log_dir=model_name + '/logs', profile_batch=0)\n",
    "   \n",
    "    history = model.fit(X_train, y_train, \n",
    "              batch_size=32, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[Metrics(valid_data=(X_valid, y_valid)),\n",
    "                         ck_callback,\n",
    "                         tb_callback])\n",
    "     '''\n",
    "    \n",
    "    model.save(model_path)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95357e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:04:46.972174Z",
     "start_time": "2022-07-29T01:46:44.171104Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#2class 5:5 BiLSTM M2\n",
    "model_path = '2class_5:5_bilstm_m2/model.h5'\n",
    "checkpoint_path = './2class_5:5_bilstm_m2/checkpoints'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
    "        val_targ = self.validation_data[1]\n",
    "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
    "            val_targ = np.argmax(val_targ, -1)\n",
    "\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='macro')\n",
    "\n",
    "        logs['val_f1'] = _val_f1\n",
    "        logs['val_recall'] = _val_recall\n",
    "        logs['val_precision'] = _val_precision\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "    # 模型儲存\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "\n",
    "# 按照 accuracy 保存模型\n",
    "ck_callback = ModelCheckpoint('./2class_5:5_bilstm_m2/checkpoints/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n",
    "                                                 monitor='accuracy',        # 改成 accuracy\n",
    "                                                 mode='max', verbose=2,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "tb_callback = TensorBoard(log_dir='./2class_5:5_bilstm_m2/logs', profile_batch=0)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=32, epochs=100,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks=[Metrics(valid_data=(X_valid, y_valid)),\n",
    "                     ck_callback,\n",
    "                     tb_callback])\n",
    "\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df03134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-29T09:42:46.743336Z",
     "start_time": "2022-07-29T09:42:46.285722Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del csv_file, csvfile\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2af50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5:5\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "x_train = x.reshape(x.shape[0], (x.shape[1]*x.shape[2]))\n",
    "\n",
    "X_train_under, y_train_under = undersample.fit_resample(x_train, y)\n",
    "X_train_under = X_train_under.reshape((X_train_under.shape[0], 108, 494))\n",
    "\n",
    "unique, counts = np.unique(y_train_under, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce349f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:25.414520Z",
     "start_time": "2022-07-31T13:58:25.408978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9da3e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:43.621255Z",
     "start_time": "2022-07-31T13:58:43.614891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78530ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T13:58:52.262824Z",
     "start_time": "2022-07-31T13:58:52.259644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_valid, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb86996",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 將 label為有與 label 為無的檔案名稱取出\n",
    "with open('file_yes.txt', 'w') as f:\n",
    "    for file in file_yes:\n",
    "        f.write(f\"{file}\\n\")\n",
    "\n",
    "with open('file_no.txt', 'w') as f:\n",
    "    for file in file_no:\n",
    "        f.write(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d8e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T14:36:19.383822Z",
     "start_time": "2022-07-31T14:36:19.376741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('audio_filename.txt', 'w') as f:\n",
    "    for file in files:\n",
    "        f.write(f\"{file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bab4cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988eed9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('audio_test.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in d.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dadd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T06:36:06.285998Z",
     "start_time": "2022-07-15T06:36:06.283837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae606f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:54:28.629073Z",
     "start_time": "2022-07-15T08:54:28.605697Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(audio_reshape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b466f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T09:00:12.420670Z",
     "start_time": "2022-07-15T09:00:11.596440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(x,y, how=\"right\", left_on=\"檔名\", right_on=\"檔名\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e9b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:40:24.457275Z",
     "start_time": "2022-07-16T05:40:24.265903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_reshape = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "#files.remove(1618243237)\n",
    "#files.remove(1618243179)\n",
    "#files.remove(1618243233)\n",
    "'''              \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45573cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:22:41.312525Z",
     "start_time": "2022-07-15T07:19:24.118302Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "audio_reshape.astype(np.float32)\n",
    "print(audio_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75774aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:45:00.617452Z",
     "start_time": "2022-07-15T08:44:32.923229Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "                \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd45fdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:14:39.842637Z",
     "start_time": "2022-07-31T16:14:37.863787Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#files\n",
    "\n",
    "import os\n",
    "# 取得 label 檔名與內容\n",
    "def get_labels_and_texts(label_path):\n",
    "    labels = []\n",
    "    labels_path = []\n",
    "    label_texts = []\n",
    "    for(dirpath, dirnames, filenames) in os.walk(label_path):\n",
    "        for filename in filenames:\n",
    "            \n",
    "            #取得 label 的完整路徑，後面進行讀檔\n",
    "            filename_path = os.path.join(dirpath, filename)\n",
    "            labels_path.append(filename_path)\n",
    "\n",
    "            #取得 label的檔名，後面對應到音檔\n",
    "            \n",
    "            try:\n",
    "                index = filename.index(\"_\")\n",
    "            except ValueError:\n",
    "                index = filename.index(\".\")\n",
    "\n",
    "            filename = filename[:index]\n",
    "            \n",
    "            labels.append(filename)\n",
    "    for label_file in labels_path:\n",
    "        #讀取 label 檔，並將 command 以 one-hot encoding 方式改寫 label\n",
    "        try:\n",
    "            with open(label_file) as fd:\n",
    "                data = json.load(fd)\n",
    "                a = 0\n",
    "                #b = 0\n",
    "                #c = 0\n",
    "                #d = 0\n",
    "                if data['command'] == 'Not Activated':\n",
    "                    a = '0'\n",
    "                else:\n",
    "                    a = '1'\n",
    "                data = [a]\n",
    "                label_texts.append(data)\n",
    "                fd.close()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return labels, label_texts\n",
    "\n",
    "label_path = 'dataset/data_sr/y_data'\n",
    "labels, label_texts = get_labels_and_texts(label_path)\n",
    "\n",
    "print(labels[0], label_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb6cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T15:47:34.083089Z",
     "start_time": "2022-07-31T15:47:25.129847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/data_sr/y_data'     \n",
    "\n",
    "#獲取該目錄下所有文件，存入列表中\n",
    "fileList = os.listdir ( path )\n",
    "\n",
    "n = 0\n",
    "for(dirpath, dirnames, filenames) in os.walk(label_path):\n",
    "    for filename in filenames:\n",
    "        \n",
    "        #取得 label 的完整路徑，後面進行讀檔\n",
    "        oldname = os.path.join(dirpath, filename)\n",
    "        \n",
    "        try:\n",
    "            index = filename.index(\"_\")\n",
    "        except ValueError:\n",
    "            index = filename.index(\".\")\n",
    "\n",
    "        filename = filename[:index]\n",
    "        \n",
    "        #print(filename)\n",
    "\n",
    "        #設置新文件名\n",
    "        newname = path + os.sep + filename + '.json'\n",
    "        print(oldname)\n",
    "        print(newname)\n",
    "        os . rename ( oldname , newname ) #用os模塊中的rename方法對文件改名print ( oldname , '======>' , newname ) \n",
    "        n += 1\n",
    "        #if n > 10: break\n",
    "\n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b26db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T15:12:49.787934Z",
     "start_time": "2022-07-14T15:12:49.782839Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#將 檔名與 label 寫入 csv 檔\n",
    "\n",
    "i = 0\n",
    "for label_text in label_texts:\n",
    "    label_text.insert(0, labels[i])\n",
    "    i+=1\n",
    "\n",
    "with open('dataset/data_sr/label_sample_twoclass.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['檔名','指令'])\n",
    "    \n",
    "    for label_text in label_texts:\n",
    "        writer.writerow(label_text)\n",
    "print(label_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a295c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:00:27.820019Z",
     "start_time": "2022-07-04T18:00:09.937313Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 將 檔名與特徵寫入 csv 檔\n",
    "\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "\n",
    "a_list = list(audio)\n",
    "i = 0\n",
    "b = {}\n",
    "c = []\n",
    "for a in a_list:\n",
    "    b = {\"檔名\":aa[i],\"特徵\": a}\n",
    "    c.append(b)\n",
    "    i+=1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open(audio_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col)\n",
    "        writer.writeheader()\n",
    "        #writer.writerow(['檔名','特徵'])\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7b43f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3D Numpy array to a CSV file\n",
    "# reshaping the array from 3D matrice to 2D matrice.\n",
    "arrReshaped = arr.reshape(arr.shape[0], -1)\n",
    "# saving reshaped array to file.\n",
    "np.savetxt(filename, arrReshaped)\n",
    "# retrieving data from file.\n",
    "loadedArr = np.loadtxt(filename)\n",
    "# This loadedArr is a 2D array, therefore we need to convert it to the original array shape.\n",
    "# reshaping to get original matrice with original shape.\n",
    "loadedOriginal = loadedArr.reshape(loadedArr.shape[0], loadedArr.shape[1] // arr.shape[2], arr.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a2fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T15:51:20.934271Z",
     "start_time": "2022-07-04T15:51:20.910371Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#load label csv into pd to preview data\n",
    "labels = pd.read_csv(label_csv_path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce388b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:01:04.486671Z",
     "start_time": "2022-07-04T18:01:04.275761Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#load audio csv into pd to preview data\n",
    "\n",
    "#audios = pd.read_csv(audio_csv_path)\n",
    "#audios\n",
    "\n",
    "\n",
    "with open(audio_csv_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    examples = list(reader)\n",
    "del examples[0]\n",
    "#print(examples)\n",
    "\n",
    "nwexamples = []\n",
    "for row in examples:\n",
    "    nwrow = []\n",
    "    for r in row:\n",
    "        #could not convert string to float:\n",
    "        r = np.array(r, dtype=np.float32)\n",
    "        nwrow.append(r)\n",
    "    nwexamples.append(nwrow)\n",
    "print(nwexamples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e50fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T21:42:15.621455Z",
     "start_time": "2022-07-14T21:33:46.140708Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m,n,r = audio.shape\n",
    "out_arr = np.column_stack((np.repeat(np.arange(m),n),audio.reshape(m*n,-1)))\n",
    "out_df = pd.DataFrame(out_arr)\n",
    "\n",
    "X = out_df[out_df.columns[:]].values   #dead kernel\n",
    "\n",
    "\n",
    "#np.savetxt('audio.csv', audio, delimiter=',')    # can't save filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:08:43.712458Z",
     "start_time": "2022-07-14T11:48:40.051336Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using python_speech_features to extract mfcc feartures\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# directory where we your .wav files are\n",
    "directoryName = \"dataset/data_sr/data\" # put your own directory here\n",
    "# directory to put our results in, you can change the name if you like\n",
    "resultsDirectory = 'dataset/data_sr/audio_sample'\n",
    "\n",
    "# make a new folder in this directory to save our results in\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "for filename in os.listdir(directoryName):\n",
    "    if filename.endswith('.wav'): # only get MFCCs from .wavs\n",
    "        # read in our file\n",
    "        \n",
    "        try:\n",
    "            (rate,sig) = wav.read(directoryName + \"/\" +filename)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # get mfcc\n",
    "        mfcc_feat = mfcc(sig,rate)\n",
    "\n",
    "        # get filterbank energies\n",
    "        fbank_feat = logfbank(sig,rate)\n",
    "        \n",
    "        # create a file to save our results in\n",
    "       \n",
    "        outputFile = resultsDirectory + \"/\" + os.path.splitext(filename)[0] + \".csv\"\n",
    "        file = open(outputFile, 'w+') # make file/over write existing file\n",
    "        numpy.savetxt(file, fbank_feat, delimiter=\",\") #save MFCCs as .csv\n",
    "        file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a1da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:06.246517Z",
     "start_time": "2022-07-14T12:12:54.273516Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read all audio sample csv\n",
    "audio_csvs_path = 'dataset/data_sr/audio_sample'\n",
    "csv = glob.glob(audio_csvs_path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "for filename in csv:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9880eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:56.187532Z",
     "start_time": "2022-07-14T12:19:56.118386Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combine all csvs into one\n",
    "def return_contents(file_name):\n",
    "    with open(file_name) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        return list(reader)\n",
    "\n",
    "all_files = os.listdir('dataset/data_sr/audio_sample')\n",
    "combined_output = []\n",
    "\n",
    "for file in all_files:\n",
    "    data = return_contents('dataset/data_sr/audio_sample/{}'.format(file))\n",
    "    for row in data:\n",
    "        combined_output.extend(row)\n",
    "\n",
    "with open('dataset/data_sr/audio_sample_2.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3d12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:52:44.864601Z",
     "start_time": "2022-07-04T07:52:44.114911Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using librosa to extract mfcc features\n",
    "x, sr = librosa.load(wavs[0])\n",
    "\n",
    "#Plot the signal:\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)\n",
    "# Zooming in\n",
    "n0 = 9000\n",
    "n1 = 9100\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(x[n0:n1])\n",
    "plt.grid()\n",
    "\n",
    "fs=10\n",
    "mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "\n",
    "print(mfccs.shape)\n",
    "#Displaying  the MFCCs:\n",
    "plt.figure(figsize=(15, 7))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558f72d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_reshaped = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "np.savetxt(\"audio.csv\", audio_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec3955",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d263b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "d = dict()\n",
    "for i in range(len(audio)):\n",
    "    d[files[i]] = audio[i]\n",
    "print(len(d))\n",
    "\n",
    "### Store dictionary d into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28e21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:05:48.906189Z",
     "start_time": "2022-07-15T02:03:31.977629Z"
    },
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audio_path = 'dataset/data_sr/data'\n",
    "\n",
    "# 將 flac 音檔轉成 wav 音檔\n",
    "def get_flacs(audio_path):\n",
    "    flacs = []\n",
    "    flac_filename = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.flac'):\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                index = filename.index(\".\")\n",
    "                    \n",
    "                filename = filename[:index]\n",
    "                flac_filename.append(filename)\n",
    "                \n",
    "                flacs.append(filename_path)\n",
    "    return flacs, flac_filename\n",
    "\n",
    "flacs,flac_filename = get_flacs(audio_path)\n",
    "\n",
    "i = 0\n",
    "for flac in flacs:\n",
    "    try:\n",
    "        audio, sr = sf.read(flac)\n",
    "    except RuntimeError:\n",
    "        print(flac)\n",
    "    sf.write(audio_path+'/'+flac_filename[i]+'.wav', audio, sr, 'PCM_16')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524d662",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df1[\"有指令\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8cd53",
   "metadata": {},
   "source": [
    "# 分出兩個類別的音檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef5971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:36:57.603159Z",
     "start_time": "2022-07-31T16:36:57.533689Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_filename = []\n",
    "audio_path = 'dataset/data_sr/x_all'\n",
    "\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                audio_filename.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ca6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:36:58.429804Z",
     "start_time": "2022-07-31T16:36:58.422324Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(audio_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea782be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:34:38.504798Z",
     "start_time": "2022-07-31T16:34:35.084160Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_str(var):\n",
    "    return str(list(np.reshape(np.asarray(var), (1, np.size(var)))[0]))[1:-1]\n",
    "\n",
    "file_yes = []\n",
    "file_no = []\n",
    "\n",
    "for index, row in y.iterrows():\n",
    "    file = to_str(row['檔名'])\n",
    "    if (row['指令']==0):\n",
    "        file_no.append(file)\n",
    "    else:\n",
    "        file_yes.append(file)\n",
    "    #print(row['檔名'], row['指令'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e3e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:12.782691Z",
     "start_time": "2022-07-31T16:37:12.777892Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(file_yes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f31f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:09.473818Z",
     "start_time": "2022-07-31T16:37:09.455383Z"
    }
   },
   "outputs": [],
   "source": [
    "setA = set(audio_filename)\n",
    "setB = set(file_yes)\n",
    "setC = set(file_no)\n",
    "\n",
    "setYes = setA & setB\n",
    "setNo = setA & setC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:37:09.957193Z",
     "start_time": "2022-07-31T16:37:09.954754Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(setYes), len(setNo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a29e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:38:05.464769Z",
     "start_time": "2022-07-31T16:38:05.462945Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "file_source = 'dataset/data_sr/x_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79940c87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:38:53.483581Z",
     "start_time": "2022-07-31T16:38:53.115729Z"
    }
   },
   "outputs": [],
   "source": [
    "file_destination = 'dataset/data_sr/x/yes'\n",
    "\n",
    "for i in setYes:\n",
    "        try:\n",
    "            shutil.move(file_source + i + '.wav', file_destination)\n",
    "        except:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e076ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T16:41:23.718186Z",
     "start_time": "2022-07-31T16:41:22.408650Z"
    }
   },
   "outputs": [],
   "source": [
    "file_destination = 'dataset/data_sr/x/no/'\n",
    "\n",
    "for i in setNo:\n",
    "        try:\n",
    "            shutil.move(file_source + i + '.wav', file_destination)\n",
    "        except:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296f43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SR",
   "language": "python",
   "name": "sr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 470.844,
   "position": {
    "height": "503.837px",
    "left": "117.998px",
    "right": "20px",
    "top": "25.9965px",
    "width": "567.995px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
