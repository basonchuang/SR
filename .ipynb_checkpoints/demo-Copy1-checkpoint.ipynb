{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad933f7",
   "metadata": {},
   "source": [
    "# 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2603f92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:03:13.615092Z",
     "start_time": "2022-07-15T02:03:11.135361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os, time, glob, json, csv\n",
    "import librosa.display\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, Embedding, GRU, SimpleRNN, Activation, Reshape\n",
    "from tensorflow import keras\n",
    "#from wave import open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110e425",
   "metadata": {},
   "source": [
    "# 限制GPU記憶體使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c794c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 23:52:21.279661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-26 23:52:21.299887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.299959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-07-26 23:52:21.300089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-26 23:52:21.301265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-26 23:52:21.302274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-26 23:52:21.302440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-26 23:52:21.303569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-26 23:52:21.304104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-26 23:52:21.306490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-26 23:52:21.306571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.306680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.306729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-07-26 23:52:21.308436: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-07-26 23:52:21.332499: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2799925000 Hz\n",
      "2022-07-26 23:52:21.333371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d1d5ec5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-26 23:52:21.333408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-26 23:52:21.333590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.333665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2022-07-26 23:52:21.333702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-26 23:52:21.333714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-26 23:52:21.333726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-26 23:52:21.333737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-26 23:52:21.333748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-26 23:52:21.333759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-26 23:52:21.333771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-26 23:52:21.333821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.333899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.333945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-07-26 23:52:21.333969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-26 23:52:21.377695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-26 23:52:21.377714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-07-26 23:52:21.377719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-07-26 23:52:21.377862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.377998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.378083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 23:52:21.378152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2022-07-26 23:52:21.379374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561d1d570370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-26 23:52:21.379382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n"
     ]
    }
   ],
   "source": [
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    physical_gpus[0],\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)] \n",
    ")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c6dc79",
   "metadata": {},
   "source": [
    "# 準備資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3290cbb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:03:13.635609Z",
     "start_time": "2022-07-15T02:03:13.633174Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#各檔案路徑\n",
    "audio_path = 'dataset/data_sr/data'\n",
    "label_path = 'dataset/data_sr/data'\n",
    "\n",
    "audio_csv_path = 'dataset/data_sr/audio_sample.csv'\n",
    "#label_csv_path = 'dataset/data_sr/label_sample.csv'\n",
    "label_csv_path = 'dataset/data_sr/label_sample_twoclass.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1dba0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:48:10.815113Z",
     "start_time": "2022-07-15T08:48:10.794037Z"
    }
   },
   "outputs": [],
   "source": [
    "y_path = label_csv_path\n",
    "y = pd.read_csv(y_path)\n",
    "y.head()\n",
    "\n",
    "name = y[y.columns[0]].values\n",
    "name = name.tolist()\n",
    "name = map(str, name)\n",
    "name = list(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399b1cd2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# wav not exists\n",
    "name.remove('1621260098')\n",
    "name.remove('1621260094')\n",
    "name.remove('1630587053')\n",
    "name.remove('1620877500')\n",
    "name.remove('1618243179')\n",
    "name.remove('1622944740')\n",
    "name.remove('1623546872')\n",
    "name.remove('1620877516')\n",
    "name.remove('1620955238')\n",
    "name.remove('1623546876')\n",
    "name.remove('1629341577')\n",
    "name.remove('1626860174')\n",
    "name.remove('1629341588')\n",
    "name.remove('1620898178')\n",
    "name.remove('1637748622')\n",
    "name.remove('1626860172')\n",
    "name.remove('1620898181')\n",
    "name.remove('1620955240')\n",
    "name.remove('1627775236')\n",
    "name.remove('1618243233')\n",
    "name.remove('1650866474')\n",
    "name.remove('1618243237')\n",
    "name.remove('1629450355')\n",
    "name.remove('1620877512')\n",
    "name.remove('1626860184')\n",
    "name.remove('1627775229')\n",
    "name.remove('1622340186')\n",
    "name.remove('1621260096')\n",
    "name.remove('1635565854')\n",
    "name.remove('1635565858')\n",
    "name.remove('1620955233')\n",
    "name.remove('1620898192')\n",
    "name.remove('1620955236')\n",
    "name.remove('1621260104')\n",
    "name.remove('1627775238')\n",
    "name.remove('1650866472')\n",
    "name.remove('1627956275')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c800ee88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:03:17.252725Z",
     "start_time": "2022-07-15T02:03:17.006141Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 取得 wav 音檔路徑\n",
    "def get_wavs(wav_path):\n",
    "    wavs = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(wav_path):\n",
    "        for n in name:\n",
    "            n = n + \".wav\"\n",
    "            filename_path = os.path.join(dirpath, n)\n",
    "            wavs.append(filename_path)\n",
    "            '''\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                wavs.append(filename_path)\n",
    "                '''\n",
    "    return wavs\n",
    "\n",
    "wavs = get_wavs(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ff661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:25:49.094803Z",
     "start_time": "2022-07-15T02:05:49.152690Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mfcc function\n",
    "# 将音频数据转为时间序列（列）和MFCC（行）的矩阵，将对应的译文转成字向量\n",
    "def get_mfccs(wavs, n_input, contexts):\n",
    "    file = []\n",
    "    audio = []\n",
    "    audio_len = []\n",
    "    \n",
    "    for wav_file in wavs:\n",
    "        # load audio and convert to features\n",
    "        audio_data = audiofile_to_input_vector(wav_file, n_input, contexts)\n",
    "        try:\n",
    "            audio_data = audio_data.astype('float32')\n",
    "            \n",
    "            file.append(wav_file)\n",
    "            audio.append(audio_data)\n",
    "            audio_len.append(np.int32(len(audio_data)))\n",
    "        except AttributeError:\n",
    "            print()\n",
    "        except FileNotFoundError:\n",
    "            print()\n",
    " \n",
    "    audio = np.asarray(audio,dtype=object)\n",
    "    audio_len = np.asarray(audio_len)\n",
    "    return file, audio, audio_len\n",
    "     \n",
    "# 将音频信息转成MFCC特征\n",
    "# 参数说明---audio_filename：音频文件   numcep：梅尔倒谱系数个数\n",
    "#       numcontext：对于每个时间段，要包含的上下文样本个数\n",
    "def audiofile_to_input_vector(audio_filename, numcep, numcontext):\n",
    "    # 加载音频文件\n",
    "    try:\n",
    "        fs, audio = wav.read(audio_filename)\n",
    "        orig_inputs = mfcc(audio, samplerate=fs, numcep=numcep)\n",
    "        # 打印MFCC系数的形状，得到比如(955, 26)的形状\n",
    "        # 955表示时间序列，26表示每个序列的MFCC的特征值为26个\n",
    "        # 这个形状因文件而异，不同文件可能有不同长度的时间序列，但是，每个序列的特征值数量都是一样的\n",
    "        #print('orig_inputs shape', np.shape(orig_inputs))\n",
    "\n",
    "        # 因为我们使用双向循环神经网络来训练,它的输出包含正、反向的结\n",
    "        # 果,相当于每一个时间序列都扩大了一倍,所以\n",
    "        # 为了保证总时序不变,使用orig_inputs =\n",
    "        # orig_inputs[::2]对orig_inputs每隔一行进行一次\n",
    "        # 取样。这样被忽略的那个序列可以用后文中反向\n",
    "        # RNN生成的输出来代替,维持了总的序列长度。\n",
    "        orig_inputs = orig_inputs[::2]  # (478, 26)\n",
    "        # print(np.shape(orig_inputs))\n",
    "        # 因为我们讲解和实际使用的numcontext=9，所以下面的备注我都以numcontext=9来讲解\n",
    "        # 这里装的就是我们要返回的数据，因为同时要考虑前9个和后9个时间序列，\n",
    "        # 所以每个时间序列组合了19*26=494个MFCC特征数\n",
    "        train_inputs = np.array([], np.float32)\n",
    "        train_inputs.resize((orig_inputs.shape[0], numcep + 2 * numcep * numcontext))\n",
    "        #print('train_inputs shape', np.shape(train_inputs))#)(478, 494)\n",
    "\n",
    "        # Prepare pre-fix post fix context\n",
    "        empty_mfcc = np.array([])\n",
    "        empty_mfcc.resize((numcep))\n",
    "\n",
    "        # Prepare train_inputs with past and future contexts\n",
    "        # time_slices保存的是时间切片，也就是有多少个时间序列\n",
    "        time_slices = range(train_inputs.shape[0])\n",
    "\n",
    "        # context_past_min和context_future_max用来计算哪些序列需要补零\n",
    "        context_past_min = time_slices[0] + numcontext\n",
    "        context_future_max = time_slices[-1] - numcontext\n",
    "\n",
    "        # 开始遍历所有序列\n",
    "        for time_slice in time_slices:\n",
    "            # 对前9个时间序列的MFCC特征补0，不需要补零的，则直接获取前9个时间序列的特征\n",
    "            need_empty_past = max(0, (context_past_min - time_slice))\n",
    "            empty_source_past = list(empty_mfcc for empty_slots in range(need_empty_past))\n",
    "            data_source_past = orig_inputs[max(0, time_slice - numcontext):time_slice]\n",
    "            assert (len(empty_source_past) + len(data_source_past) == numcontext)\n",
    "\n",
    "            # 对后9个时间序列的MFCC特征补0，不需要补零的，则直接获取后9个时间序列的特征\n",
    "            need_empty_future = max(0, (time_slice - context_future_max))\n",
    "            empty_source_future = list(empty_mfcc for empty_slots in range(need_empty_future))\n",
    "            data_source_future = orig_inputs[time_slice + 1:time_slice + numcontext + 1]\n",
    "            assert (len(empty_source_future) + len(data_source_future) == numcontext)\n",
    "\n",
    "            # 前9个时间序列的特征\n",
    "            if need_empty_past:\n",
    "                past = np.concatenate((empty_source_past, data_source_past))\n",
    "            else:\n",
    "                past = data_source_past\n",
    "            # 后9个时间序列的特征\n",
    "            if need_empty_future:\n",
    "                future = np.concatenate((data_source_future, empty_source_future))\n",
    "            else:\n",
    "                future = data_source_future\n",
    "\n",
    "            # 将前9个时间序列和当前时间序列以及后9个时间序列组合\n",
    "            past = np.reshape(past, numcontext * numcep)\n",
    "            now = orig_inputs[time_slice]\n",
    "            future = np.reshape(future, numcontext * numcep)\n",
    "\n",
    "            train_inputs[time_slice] = np.concatenate((past, now, future))\n",
    "            assert (len(train_inputs[time_slice]) == numcep + 2 * numcep * numcontext)\n",
    "\n",
    "        # 将数据使用正太分布标准化，减去均值然后再除以方差\n",
    "        train_inputs = (train_inputs - np.mean(train_inputs)) / np.std(train_inputs)\n",
    "\n",
    "        return train_inputs\n",
    "    except ValueError:\n",
    "        print(audio_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(audio_filename)\n",
    "    \n",
    " \n",
    "#对齐处理\n",
    "def pad_sequences(sequences, maxlen=None, dtype=np.float32,\n",
    "                  padding='post', truncating='post', value=0.):\n",
    "    #[478 512 503 406 481 509 422 465]\n",
    "    lengths = np.asarray([len(s) for s in sequences], dtype=np.int64)\n",
    " \n",
    "    nb_samples = len(sequences)\n",
    " \n",
    "    #maxlen，该批次中，最长的序列长度\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    " \n",
    "    # 在下面的主循环中，从第一个非空序列中获取样本形状以检查一致性\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    " \n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # 序列为空，跳过\n",
    " \n",
    "        #post表示后补零，pre表示前补零\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    " \n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    " \n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    " \n",
    "    return x, lengths\n",
    "\n",
    "\n",
    "# 梅尔倒谱系数的个数\n",
    "n_input = 26\n",
    "# 对于每个时间序列，要包含上下文样本的个数\n",
    "contexts = 9\n",
    "\n",
    "file, audio, audio_len = get_mfccs(wavs, n_input, contexts)\n",
    "audio, audio_len = pad_sequences(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(name)\n",
    "\n",
    "df.columns=[\"filename\"]\n",
    "df[\"filename\"] = df[\"filename\"].astype(int)\n",
    "\n",
    "df1 = pd.concat([df,y], axis=\"columns\")\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eede59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "031347b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91111, 1)\n"
     ]
    }
   ],
   "source": [
    "# 音檔的 label\n",
    "y = df1.drop([\"filename\"], axis=1)\n",
    "#y.shape\n",
    "y = y[y.columns[1:6]].values\n",
    "print(y.shape)\n",
    "y = y.tolist()\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60fb13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = audio.reshape((91111, 108, 494))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93e665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(x, y, test_size=0.4, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90599b2a",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cac12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### 1 \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = 100, output_dim = 20, input_shape=(108, 494, )))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.summary()\n",
    "'''\n",
    "#model.add(Embedding(input_dim = 100, output_dim = 20, input_shape=(108, 494, )))\n",
    "'''\n",
    "### 2\n",
    "HIDDEN_LAYERS = 4\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=108, units=4))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Reshape((1,4)))\n",
    "model.add(SimpleRNN(4))\n",
    "model.add(Dense(units=2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()\n",
    "'''\n",
    "\n",
    "'''\n",
    "### 3\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
    ")\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05c3218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 20)          2000      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, None, 16)          336       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 2,392\n",
      "Trainable params: 2,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = 100, output_dim = 20))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Reshape((1,4)))\n",
    "model.add(SimpleRNN(4))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "baeccf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90aa481",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26a6c55f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_14_input to have 2 dimensions, but got array with shape (54666, 108, 494)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ck_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/checkpoints/weights.\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{val_f1:.4f}\u001b[39;00m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                                  monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m                                                  mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                                  save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                                                  save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m tb_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/logs\u001b[39m\u001b[38;5;124m'\u001b[39m, profile_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/model_rnn_2class_orig.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path)\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:1150\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_generator(\n\u001b[1;32m   1134\u001b[0m         x,\n\u001b[1;32m   1135\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   1147\u001b[0m         initial_epoch\u001b[38;5;241m=\u001b[39minitial_epoch)\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;66;03m# Case 2: Symbolic tensors or Numpy array-like.\u001b[39;00m\n\u001b[0;32m-> 1150\u001b[0m x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_user_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# Prepare validation data.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m do_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training.py:574\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    571\u001b[0m     feed_input_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_input_shapes\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeed_input_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_graph_network:\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/training_utils.py:131\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m shape \u001b[38;5;241m=\u001b[39m shapes[i]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[i]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError when checking \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m exception_prefix \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m names[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shape)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dimensions, but got array \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(data_shape))\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_batch_axis:\n\u001b[1;32m    137\u001b[0m     data_shape \u001b[38;5;241m=\u001b[39m data_shape[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_14_input to have 2 dimensions, but got array with shape (54666, 108, 494)"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./model/checkpoints'):\n",
    "    os.makedirs('./model/checkpoints')\n",
    "\n",
    "# 按照 val_f1 保存模型\n",
    "ck_callback = tf.keras.callbacks.ModelCheckpoint('./model/checkpoints/weights.{epoch:02d}-{val_f1:.4f}.hdf5',\n",
    "                                                 monitor='val_f1', \n",
    "                                                 mode='max', verbose=2,\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_weights_only=True)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./model/logs', profile_batch=0)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=20)\n",
    "model_path = 'model/model_rnn_2class_orig.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74477b0",
   "metadata": {},
   "source": [
    "# 模型評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "922a5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 載入模型\n",
    "model_path = 'model/model.h5'\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e45334fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bason/.conda/envs/SR/lib/python3.8/site-packages/keras/engine/saving.py:164: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6ab5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b5f1441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 09:26:54.934764: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 11666161728 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:941 test_function  *\n        outputs = self.distribute_strategy.run(\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:911 test_step  **\n        self.compiled_loss(\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/nn_impl.py:171 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 4) vs (None, 1))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1081\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m traceme\u001b[38;5;241m.\u001b[39mTraceMe(\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1078\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1079\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep):\n\u001b[1;32m   1080\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1081\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m   \u001b[38;5;66;03m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m   \u001b[38;5;66;03m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m   \u001b[38;5;66;03m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39minferred_steps:\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:580\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count():\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_counter\u001b[38;5;241m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:627\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 627\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    630\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:505\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    509\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2446\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2445\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2446\u001b[0m   graph_function, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2777\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2774\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(args, kwargs)\n\u001b[1;32m   2776\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 2777\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   2779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, args, kwargs\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2657\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2652\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2654\u001b[0m ]\n\u001b[1;32m   2655\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   2656\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2662\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2665\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2666\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2668\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   2669\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2671\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2672\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2673\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2674\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:981\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 981\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    986\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:441\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# We register a variable creator with reduced priority. If an outer\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# variable creator is just modifying keyword arguments to the variable\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# constructor, this will work harmoniously. Since the `scope` registered\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# better than the alternative, tracing the initialization graph but giving\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# the user a variable type they didn't want.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    439\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:968\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    969\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:941 test_function  *\n        outputs = self.distribute_strategy.run(\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:911 test_step  **\n        self.compiled_loss(\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1595 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4692 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    /home/bason/.conda/envs/SR/lib/python3.8/site-packages/tensorflow/python/ops/nn_impl.py:171 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 4) vs (None, 1))\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e9a2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18222/18222 [==============================] - 2s 88us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17106951463400447, 0.9271210432052612]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29a49558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18223/18223 [==============================] - 2s 88us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17132094184849792, 0.9254788160324097]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "165cf901",
   "metadata": {},
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0988eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('audio_test.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in d.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "910dadd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T06:36:06.285998Z",
     "start_time": "2022-07-15T06:36:06.283837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91111, 108, 494)\n"
     ]
    }
   ],
   "source": [
    "print(audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae606f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:54:28.629073Z",
     "start_time": "2022-07-15T08:54:28.605697Z"
    }
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(audio_reshape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b466f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T09:00:12.420670Z",
     "start_time": "2022-07-15T09:00:11.596440Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(x,y, how=\"right\", left_on=\"檔名\", right_on=\"檔名\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e9b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T05:40:24.457275Z",
     "start_time": "2022-07-16T05:40:24.265903Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_reshape = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "#files.remove(1618243237)\n",
    "#files.remove(1618243179)\n",
    "#files.remove(1618243233)\n",
    "'''              \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45573cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:22:41.312525Z",
     "start_time": "2022-07-15T07:19:24.118302Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "audio_reshape.astype(np.float32)\n",
    "print(audio_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75774aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T08:45:00.617452Z",
     "start_time": "2022-07-15T08:44:32.923229Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "                \n",
    "b = {}\n",
    "c = []\n",
    "i = 0\n",
    "for a in aa:\n",
    "    b = {\"檔名\":aa[i], \"特徵\":(audio_reshape)}\n",
    "    c.append(b)\n",
    "    i += 1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open('audio_csv.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col, delimiter =\",\")\n",
    "        writer.writeheader()\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dd45fdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:03:16.829581Z",
     "start_time": "2022-07-15T02:03:13.654679Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633056677 [1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 取得 label 檔名與內容\n",
    "def get_labels_and_texts(label_path):\n",
    "    labels = []\n",
    "    labels_path = []\n",
    "    label_texts = []\n",
    "    for(dirpath, dirnames, filenames) in os.walk(label_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.json'):\n",
    "                #取得 label 的完整路徑，後面進行讀檔\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                labels_path.append(filename_path)\n",
    "                \n",
    "                #取得 label的檔名，後面對應到音檔\n",
    "                try:\n",
    "                    index = filename.index(\"_\")\n",
    "                except ValueError:\n",
    "                    index = filename.index(\".\")\n",
    "                    \n",
    "                filename = filename[:index]\n",
    "                labels.append(filename)\n",
    "    for label_file in labels_path:\n",
    "        #讀取 label 檔，並將 command 以 one-hot encoding 方式改寫 label\n",
    "        try:\n",
    "            with open(label_file) as fd:\n",
    "                data = json.load(fd)\n",
    "                a = 0\n",
    "                b = 0\n",
    "                #c = 0\n",
    "                #d = 0\n",
    "                if data['command'] == 'Not Activated':\n",
    "                    a = 1\n",
    "                else:\n",
    "                    b = 1\n",
    "                data = [a, b]\n",
    "                label_texts.append(data)\n",
    "                fd.close()\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return labels, label_texts\n",
    "\n",
    "labels, label_texts = get_labels_and_texts(label_path)\n",
    "\n",
    "print(labels[0], label_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e00b26db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T15:12:49.787934Z",
     "start_time": "2022-07-14T15:12:49.782839Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1633056677', 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#將 檔名與 label 寫入 csv 檔\n",
    "\n",
    "i = 0\n",
    "for label_text in label_texts:\n",
    "    label_text.insert(0, labels[i])\n",
    "    i+=1\n",
    "\n",
    "with open('dataset/data_sr/label_sample_twoclass.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['檔名','沒指令','有指令'])\n",
    "    \n",
    "    for label_text in label_texts:\n",
    "        writer.writerow(label_text)\n",
    "print(label_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a295c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:00:27.820019Z",
     "start_time": "2022-07-04T18:00:09.937313Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 將 檔名與特徵寫入 csv 檔\n",
    "\n",
    "aa = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                aa.append(filename)\n",
    "\n",
    "a_list = list(audio)\n",
    "i = 0\n",
    "b = {}\n",
    "c = []\n",
    "for a in a_list:\n",
    "    b = {\"檔名\":aa[i],\"特徵\": a}\n",
    "    c.append(b)\n",
    "    i+=1\n",
    "col = [\"檔名\", \"特徵\"]\n",
    "try:\n",
    "    with open(audio_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=col)\n",
    "        writer.writeheader()\n",
    "        #writer.writerow(['檔名','特徵'])\n",
    "\n",
    "        for data in c:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a2fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T15:51:20.934271Z",
     "start_time": "2022-07-04T15:51:20.910371Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#load label csv into pd to preview data\n",
    "labels = pd.read_csv(label_csv_path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce388b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T18:01:04.486671Z",
     "start_time": "2022-07-04T18:01:04.275761Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#load audio csv into pd to preview data\n",
    "audios = pd.read_csv(audio_csv_path)\n",
    "audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e50fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T21:42:15.621455Z",
     "start_time": "2022-07-14T21:33:46.140708Z"
    }
   },
   "outputs": [],
   "source": [
    "m,n,r = audio.shape\n",
    "out_arr = np.column_stack((np.repeat(np.arange(m),n),audio.reshape(m*n,-1)))\n",
    "out_df = pd.DataFrame(out_arr)\n",
    "\n",
    "X = out_df[out_df.columns[:]].values   #dead kernel\n",
    "\n",
    "\n",
    "#np.savetxt('audio.csv', audio, delimiter=',')    # can't save filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:08:43.712458Z",
     "start_time": "2022-07-14T11:48:40.051336Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using python_speech_features to extract mfcc feartures\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# directory where we your .wav files are\n",
    "directoryName = \"dataset/data_sr/data\" # put your own directory here\n",
    "# directory to put our results in, you can change the name if you like\n",
    "resultsDirectory = 'dataset/data_sr/audio_sample'\n",
    "\n",
    "# make a new folder in this directory to save our results in\n",
    "if not os.path.exists(resultsDirectory):\n",
    "    os.makedirs(resultsDirectory)\n",
    "\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "for filename in os.listdir(directoryName):\n",
    "    if filename.endswith('.wav'): # only get MFCCs from .wavs\n",
    "        # read in our file\n",
    "        \n",
    "        try:\n",
    "            (rate,sig) = wav.read(directoryName + \"/\" +filename)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # get mfcc\n",
    "        mfcc_feat = mfcc(sig,rate)\n",
    "\n",
    "        # get filterbank energies\n",
    "        fbank_feat = logfbank(sig,rate)\n",
    "        \n",
    "        # create a file to save our results in\n",
    "       \n",
    "        outputFile = resultsDirectory + \"/\" + os.path.splitext(filename)[0] + \".csv\"\n",
    "        file = open(outputFile, 'w+') # make file/over write existing file\n",
    "        numpy.savetxt(file, fbank_feat, delimiter=\",\") #save MFCCs as .csv\n",
    "        file.close() # close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a1da8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:06.246517Z",
     "start_time": "2022-07-14T12:12:54.273516Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# read all audio sample csv\n",
    "audio_csvs_path = 'dataset/data_sr/audio_sample'\n",
    "csv = glob.glob(audio_csvs_path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "for filename in csv:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9880eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T12:19:56.187532Z",
     "start_time": "2022-07-14T12:19:56.118386Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# combine all csvs into one\n",
    "def return_contents(file_name):\n",
    "    with open(file_name) as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        return list(reader)\n",
    "\n",
    "all_files = os.listdir('dataset/data_sr/audio_sample')\n",
    "combined_output = []\n",
    "\n",
    "for file in all_files:\n",
    "    data = return_contents('dataset/data_sr/audio_sample/{}'.format(file))\n",
    "    for row in data:\n",
    "        combined_output.extend(row)\n",
    "\n",
    "with open('dataset/data_sr/audio_sample_2.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3d12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T07:52:44.864601Z",
     "start_time": "2022-07-04T07:52:44.114911Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using librosa to extract mfcc features\n",
    "x, sr = librosa.load(wavs[0])\n",
    "\n",
    "#Plot the signal:\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)\n",
    "# Zooming in\n",
    "n0 = 9000\n",
    "n1 = 9100\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(x[n0:n1])\n",
    "plt.grid()\n",
    "\n",
    "fs=10\n",
    "mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "\n",
    "print(mfccs.shape)\n",
    "#Displaying  the MFCCs:\n",
    "plt.figure(figsize=(15, 7))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_reshaped = audio.reshape(audio.shape[0], -1)\n",
    "\n",
    "np.savetxt(\"audio.csv\", audio_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec3955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b7d263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85484\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "for(dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "    for filename in filenames:\n",
    "            if filename.endswith('.wav') or filename.endswith('.WAV'):                \n",
    "                #取得 wav的檔名\n",
    "                index = filename.index('.')\n",
    "                filename = filename[:index]\n",
    "                files.append(filename)\n",
    "                \n",
    "d = dict()\n",
    "for i in range(len(audio)):\n",
    "    d[files[i]] = audio[i]\n",
    "print(len(d))\n",
    "\n",
    "### Store dictionary d into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb28e21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T02:05:48.906189Z",
     "start_time": "2022-07-15T02:03:31.977629Z"
    },
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/data_sr/data/1623372994.flac\n",
      "dataset/data_sr/data/1623373198.flac\n",
      "dataset/data_sr/data/1624246529.flac\n",
      "dataset/data_sr/data/1619576718.flac\n",
      "dataset/data_sr/data/1623373076.flac\n",
      "dataset/data_sr/data/1623373306.flac\n",
      "dataset/data_sr/data/1620697758.flac\n",
      "dataset/data_sr/data/1624246517.flac\n",
      "dataset/data_sr/data/1620697415.flac\n",
      "dataset/data_sr/data/1620697761.flac\n",
      "dataset/data_sr/data/1620698062.flac\n",
      "dataset/data_sr/data/1623373169.flac\n",
      "dataset/data_sr/data/1620698334.flac\n",
      "dataset/data_sr/data/1623373060.flac\n",
      "dataset/data_sr/data/1620697764.flac\n",
      "dataset/data_sr/data/1623372974.flac\n",
      "dataset/data_sr/data/1620697767.flac\n",
      "dataset/data_sr/data/1620697512.flac\n"
     ]
    }
   ],
   "source": [
    "# 將 flac 音檔轉成 wav 音檔\n",
    "def get_flacs(audio_path):\n",
    "    flacs = []\n",
    "    flac_filename = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(audio_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.flac'):\n",
    "                filename_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                index = filename.index(\".\")\n",
    "                    \n",
    "                filename = filename[:index]\n",
    "                flac_filename.append(filename)\n",
    "                \n",
    "                flacs.append(filename_path)\n",
    "    return flacs, flac_filename\n",
    "\n",
    "flacs,flac_filename = get_flacs(audio_path)\n",
    "\n",
    "i = 0\n",
    "for flac in flacs:\n",
    "    try:\n",
    "        audio, sr = sf.read(flac)\n",
    "    except RuntimeError:\n",
    "        print(flac)\n",
    "    sf.write(audio_path+'/'+flac_filename[i]+'.wav', audio, sr, 'PCM_16')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SR",
   "language": "python",
   "name": "sr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
